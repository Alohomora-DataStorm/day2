{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "915bcf66-2c9e-423f-b2e9-7b1cabee6602",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "5b58b633-4bde-4545-81e2-566bbe38e10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_transactions = pd.read_csv(\"Historical-transaction-data.csv\")\n",
    "store_info = pd.read_csv(\"Store-info.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "1ec8840e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shop_id</th>\n",
       "      <th>shop_area_sq_ft</th>\n",
       "      <th>shop_profile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SHOP047</td>\n",
       "      <td>528</td>\n",
       "      <td>Moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SHOP009</td>\n",
       "      <td>676</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SHOP083</td>\n",
       "      <td>676</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SHOP117</td>\n",
       "      <td>676</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SHOP042</td>\n",
       "      <td>676</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   shop_id  shop_area_sq_ft shop_profile\n",
       "0  SHOP047              528     Moderate\n",
       "1  SHOP009              676         High\n",
       "2  SHOP083              676          Low\n",
       "3  SHOP117              676          Low\n",
       "4  SHOP042              676          Low"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "893725f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_description</th>\n",
       "      <th>transaction_date</th>\n",
       "      <th>invoice_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_price</th>\n",
       "      <th>quantity_sold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ORANGE BARLEY 1.5L</td>\n",
       "      <td>2021-12-11T00:00:00.000Z</td>\n",
       "      <td>147.0</td>\n",
       "      <td>BGXA</td>\n",
       "      <td>SHOP008</td>\n",
       "      <td>220</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GINGER BEER 1.5L</td>\n",
       "      <td>2021-10-17T00:00:00.000Z</td>\n",
       "      <td>371.0</td>\n",
       "      <td>IA25</td>\n",
       "      <td>SHOP112</td>\n",
       "      <td>220</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TONIC PET 500ML</td>\n",
       "      <td>2021-12-13T00:00:00.000Z</td>\n",
       "      <td>484.0</td>\n",
       "      <td>VN7V</td>\n",
       "      <td>SHOP008</td>\n",
       "      <td>160</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CREAM SODA 1L</td>\n",
       "      <td>2021-12-13T00:00:00.000Z</td>\n",
       "      <td>484.0</td>\n",
       "      <td>VN7V</td>\n",
       "      <td>SHOP008</td>\n",
       "      <td>150</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>STRAWBERRY MILK 180ML</td>\n",
       "      <td>2021-10-23T00:00:00.000Z</td>\n",
       "      <td>1310.0</td>\n",
       "      <td>7S00</td>\n",
       "      <td>SHOP112</td>\n",
       "      <td>210</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        item_description          transaction_date  invoice_id customer_id  \\\n",
       "0     ORANGE BARLEY 1.5L  2021-12-11T00:00:00.000Z       147.0        BGXA   \n",
       "1       GINGER BEER 1.5L  2021-10-17T00:00:00.000Z       371.0        IA25   \n",
       "2        TONIC PET 500ML  2021-12-13T00:00:00.000Z       484.0        VN7V   \n",
       "3          CREAM SODA 1L  2021-12-13T00:00:00.000Z       484.0        VN7V   \n",
       "4  STRAWBERRY MILK 180ML  2021-10-23T00:00:00.000Z      1310.0        7S00   \n",
       "\n",
       "   shop_id  item_price  quantity_sold  \n",
       "0  SHOP008         220              2  \n",
       "1  SHOP112         220              2  \n",
       "2  SHOP008         160              2  \n",
       "3  SHOP008         150              2  \n",
       "4  SHOP112         210              5  "
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "historical_transactions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "0d74c899",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = pd.merge(historical_transactions, store_info, on=\"shop_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "332eef63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_description</th>\n",
       "      <th>transaction_date</th>\n",
       "      <th>invoice_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_price</th>\n",
       "      <th>quantity_sold</th>\n",
       "      <th>shop_area_sq_ft</th>\n",
       "      <th>shop_profile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ORANGE BARLEY 1.5L</td>\n",
       "      <td>2021-12-11T00:00:00.000Z</td>\n",
       "      <td>147.0</td>\n",
       "      <td>BGXA</td>\n",
       "      <td>SHOP008</td>\n",
       "      <td>220</td>\n",
       "      <td>2</td>\n",
       "      <td>678</td>\n",
       "      <td>Moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TONIC PET 500ML</td>\n",
       "      <td>2021-12-13T00:00:00.000Z</td>\n",
       "      <td>484.0</td>\n",
       "      <td>VN7V</td>\n",
       "      <td>SHOP008</td>\n",
       "      <td>160</td>\n",
       "      <td>2</td>\n",
       "      <td>678</td>\n",
       "      <td>Moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CREAM SODA 1L</td>\n",
       "      <td>2021-12-13T00:00:00.000Z</td>\n",
       "      <td>484.0</td>\n",
       "      <td>VN7V</td>\n",
       "      <td>SHOP008</td>\n",
       "      <td>150</td>\n",
       "      <td>2</td>\n",
       "      <td>678</td>\n",
       "      <td>Moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GINGER BEER 1.5L</td>\n",
       "      <td>2021-12-10T00:00:00.000Z</td>\n",
       "      <td>1000053.0</td>\n",
       "      <td>VT9C</td>\n",
       "      <td>SHOP008</td>\n",
       "      <td>220</td>\n",
       "      <td>1</td>\n",
       "      <td>678</td>\n",
       "      <td>Moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GINGER BEER 1.5L</td>\n",
       "      <td>2021-12-10T00:00:00.000Z</td>\n",
       "      <td>1000057.0</td>\n",
       "      <td>8QLS</td>\n",
       "      <td>SHOP008</td>\n",
       "      <td>440</td>\n",
       "      <td>1</td>\n",
       "      <td>678</td>\n",
       "      <td>Moderate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     item_description          transaction_date  invoice_id customer_id  \\\n",
       "0  ORANGE BARLEY 1.5L  2021-12-11T00:00:00.000Z       147.0        BGXA   \n",
       "1     TONIC PET 500ML  2021-12-13T00:00:00.000Z       484.0        VN7V   \n",
       "2       CREAM SODA 1L  2021-12-13T00:00:00.000Z       484.0        VN7V   \n",
       "3    GINGER BEER 1.5L  2021-12-10T00:00:00.000Z   1000053.0        VT9C   \n",
       "4    GINGER BEER 1.5L  2021-12-10T00:00:00.000Z   1000057.0        8QLS   \n",
       "\n",
       "   shop_id  item_price  quantity_sold  shop_area_sq_ft shop_profile  \n",
       "0  SHOP008         220              2              678     Moderate  \n",
       "1  SHOP008         160              2              678     Moderate  \n",
       "2  SHOP008         150              2              678     Moderate  \n",
       "3  SHOP008         220              1              678     Moderate  \n",
       "4  SHOP008         440              1              678     Moderate  "
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "32f40270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert transaction_date to datetime format\n",
    "merged_data['transaction_date'] = pd.to_datetime(merged_data['transaction_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "61091eb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 473974 entries, 0 to 473973\n",
      "Data columns (total 9 columns):\n",
      " #   Column            Non-Null Count   Dtype              \n",
      "---  ------            --------------   -----              \n",
      " 0   item_description  438046 non-null  object             \n",
      " 1   transaction_date  473974 non-null  datetime64[ns, UTC]\n",
      " 2   invoice_id        467654 non-null  float64            \n",
      " 3   customer_id       473974 non-null  object             \n",
      " 4   shop_id           473974 non-null  object             \n",
      " 5   item_price        473974 non-null  int64              \n",
      " 6   quantity_sold     473974 non-null  int64              \n",
      " 7   shop_area_sq_ft   473974 non-null  int64              \n",
      " 8   shop_profile      387341 non-null  object             \n",
      "dtypes: datetime64[ns, UTC](1), float64(1), int64(3), object(4)\n",
      "memory usage: 36.2+ MB\n"
     ]
    }
   ],
   "source": [
    "merged_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "95ea7364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "item_description    35928\n",
       "transaction_date        0\n",
       "invoice_id           6320\n",
       "customer_id             0\n",
       "shop_id                 0\n",
       "item_price              0\n",
       "quantity_sold           0\n",
       "shop_area_sq_ft         0\n",
       "shop_profile        86633\n",
       "dtype: int64"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "111ecae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate sales per transaction\n",
    "merged_data['sales'] = merged_data['item_price'] * merged_data['quantity_sold']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "caf359c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "store_metrics = merged_data.groupby('shop_id').agg({\n",
    "    'sales': 'sum',\n",
    "    'invoice_id': 'count',\n",
    "    'customer_id': pd.Series.nunique\n",
    "}).reset_index()\n",
    "\n",
    "store_metrics.columns = ['shop_id', 'total_sales', 'transaction_count', 'unique_customers']\n",
    "store_metrics['avg_transaction_value'] = store_metrics['total_sales'] / store_metrics['transaction_count']\n",
    "store_metrics['avg_sales_per_customer'] = store_metrics['total_sales'] / store_metrics['unique_customers']\n",
    "\n",
    "# Merge the store_metrics dataframe with store_info dataframe\n",
    "store_profile_data = pd.merge(store_info, store_metrics, on=\"shop_id\")\n",
    "\n",
    "# Calculate sales per square foot\n",
    "store_profile_data['sales_per_sq_ft'] = store_profile_data['total_sales'] / store_profile_data['shop_area_sq_ft']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "e31c4adf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shop_id</th>\n",
       "      <th>shop_area_sq_ft</th>\n",
       "      <th>shop_profile</th>\n",
       "      <th>total_sales</th>\n",
       "      <th>transaction_count</th>\n",
       "      <th>unique_customers</th>\n",
       "      <th>avg_transaction_value</th>\n",
       "      <th>avg_sales_per_customer</th>\n",
       "      <th>sales_per_sq_ft</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SHOP047</td>\n",
       "      <td>528</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>842960</td>\n",
       "      <td>1687</td>\n",
       "      <td>928</td>\n",
       "      <td>499.679905</td>\n",
       "      <td>908.362069</td>\n",
       "      <td>1596.515152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SHOP009</td>\n",
       "      <td>676</td>\n",
       "      <td>High</td>\n",
       "      <td>1970870</td>\n",
       "      <td>4521</td>\n",
       "      <td>2498</td>\n",
       "      <td>435.936740</td>\n",
       "      <td>788.979183</td>\n",
       "      <td>2915.488166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SHOP083</td>\n",
       "      <td>676</td>\n",
       "      <td>Low</td>\n",
       "      <td>1691985</td>\n",
       "      <td>3583</td>\n",
       "      <td>1900</td>\n",
       "      <td>472.225788</td>\n",
       "      <td>890.518421</td>\n",
       "      <td>2502.936391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SHOP117</td>\n",
       "      <td>676</td>\n",
       "      <td>Low</td>\n",
       "      <td>2325980</td>\n",
       "      <td>4023</td>\n",
       "      <td>2037</td>\n",
       "      <td>578.170520</td>\n",
       "      <td>1141.865488</td>\n",
       "      <td>3440.798817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SHOP042</td>\n",
       "      <td>676</td>\n",
       "      <td>Low</td>\n",
       "      <td>1340215</td>\n",
       "      <td>3232</td>\n",
       "      <td>1841</td>\n",
       "      <td>414.670483</td>\n",
       "      <td>727.982075</td>\n",
       "      <td>1982.566568</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   shop_id  shop_area_sq_ft shop_profile  total_sales  transaction_count  \\\n",
       "0  SHOP047              528     Moderate       842960               1687   \n",
       "1  SHOP009              676         High      1970870               4521   \n",
       "2  SHOP083              676          Low      1691985               3583   \n",
       "3  SHOP117              676          Low      2325980               4023   \n",
       "4  SHOP042              676          Low      1340215               3232   \n",
       "\n",
       "   unique_customers  avg_transaction_value  avg_sales_per_customer  \\\n",
       "0               928             499.679905              908.362069   \n",
       "1              2498             435.936740              788.979183   \n",
       "2              1900             472.225788              890.518421   \n",
       "3              2037             578.170520             1141.865488   \n",
       "4              1841             414.670483              727.982075   \n",
       "\n",
       "   sales_per_sq_ft  \n",
       "0      1596.515152  \n",
       "1      2915.488166  \n",
       "2      2502.936391  \n",
       "3      3440.798817  \n",
       "4      1982.566568  "
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store_profile_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "e45f4c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 124 entries, 0 to 123\n",
      "Data columns (total 9 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   shop_id                 124 non-null    object \n",
      " 1   shop_area_sq_ft         124 non-null    int64  \n",
      " 2   shop_profile            100 non-null    object \n",
      " 3   total_sales             124 non-null    int64  \n",
      " 4   transaction_count       124 non-null    int64  \n",
      " 5   unique_customers        124 non-null    int64  \n",
      " 6   avg_transaction_value   124 non-null    float64\n",
      " 7   avg_sales_per_customer  124 non-null    float64\n",
      " 8   sales_per_sq_ft         124 non-null    float64\n",
      "dtypes: float64(3), int64(4), object(2)\n",
      "memory usage: 9.7+ KB\n"
     ]
    }
   ],
   "source": [
    "store_profile_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "ca1c1263",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "shop_id                    0\n",
       "shop_area_sq_ft            0\n",
       "shop_profile              24\n",
       "total_sales                0\n",
       "transaction_count          0\n",
       "unique_customers           0\n",
       "avg_transaction_value      0\n",
       "avg_sales_per_customer     0\n",
       "sales_per_sq_ft            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store_profile_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "6ad9f816",
   "metadata": {},
   "outputs": [],
   "source": [
    "store_profile_data = store_profile_data.dropna(subset=['shop_profile'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "af490113",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "shop_id                    0\n",
       "shop_area_sq_ft            0\n",
       "shop_profile              24\n",
       "total_sales                0\n",
       "transaction_count          0\n",
       "unique_customers           0\n",
       "avg_transaction_value      0\n",
       "avg_sales_per_customer     0\n",
       "sales_per_sq_ft            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store_profile_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "a237ec98",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = store_profile_data[['total_sales', 'transaction_count', 'unique_customers', 'avg_transaction_value', 'avg_sales_per_customer', 'shop_area_sq_ft', 'sales_per_sq_ft']]\n",
    "y = store_profile_data['shop_profile']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "54cfd6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "9713e391",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data['day_of_week'] = merged_data['transaction_date'].dt.dayofweek\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "f2fff8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data['month'] = merged_data['transaction_date'].dt.month\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "25712c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def month_to_season(month):\n",
    "    if month in [3, 4, 5]:\n",
    "        return 'spring'\n",
    "    elif month in [6, 7, 8]:\n",
    "        return 'summer'\n",
    "    elif month in [9, 10, 11]:\n",
    "        return 'fall'\n",
    "    else:\n",
    "        return 'winter'\n",
    "\n",
    "merged_data['season'] = merged_data['month'].apply(month_to_season)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "b1bbd2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding for day_of_week and season\n",
    "merged_data = pd.get_dummies(merged_data, columns=['day_of_week', 'season'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "83786266",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_description</th>\n",
       "      <th>transaction_date</th>\n",
       "      <th>invoice_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_price</th>\n",
       "      <th>quantity_sold</th>\n",
       "      <th>shop_area_sq_ft</th>\n",
       "      <th>shop_profile</th>\n",
       "      <th>sales</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week_0</th>\n",
       "      <th>day_of_week_1</th>\n",
       "      <th>day_of_week_2</th>\n",
       "      <th>day_of_week_3</th>\n",
       "      <th>day_of_week_4</th>\n",
       "      <th>day_of_week_5</th>\n",
       "      <th>day_of_week_6</th>\n",
       "      <th>season_fall</th>\n",
       "      <th>season_winter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ORANGE BARLEY 1.5L</td>\n",
       "      <td>2021-12-11 00:00:00+00:00</td>\n",
       "      <td>147.0</td>\n",
       "      <td>BGXA</td>\n",
       "      <td>SHOP008</td>\n",
       "      <td>220</td>\n",
       "      <td>2</td>\n",
       "      <td>678</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>440</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TONIC PET 500ML</td>\n",
       "      <td>2021-12-13 00:00:00+00:00</td>\n",
       "      <td>484.0</td>\n",
       "      <td>VN7V</td>\n",
       "      <td>SHOP008</td>\n",
       "      <td>160</td>\n",
       "      <td>2</td>\n",
       "      <td>678</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>320</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CREAM SODA 1L</td>\n",
       "      <td>2021-12-13 00:00:00+00:00</td>\n",
       "      <td>484.0</td>\n",
       "      <td>VN7V</td>\n",
       "      <td>SHOP008</td>\n",
       "      <td>150</td>\n",
       "      <td>2</td>\n",
       "      <td>678</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>300</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GINGER BEER 1.5L</td>\n",
       "      <td>2021-12-10 00:00:00+00:00</td>\n",
       "      <td>1000053.0</td>\n",
       "      <td>VT9C</td>\n",
       "      <td>SHOP008</td>\n",
       "      <td>220</td>\n",
       "      <td>1</td>\n",
       "      <td>678</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>220</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GINGER BEER 1.5L</td>\n",
       "      <td>2021-12-10 00:00:00+00:00</td>\n",
       "      <td>1000057.0</td>\n",
       "      <td>8QLS</td>\n",
       "      <td>SHOP008</td>\n",
       "      <td>440</td>\n",
       "      <td>1</td>\n",
       "      <td>678</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>440</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     item_description          transaction_date  invoice_id customer_id  \\\n",
       "0  ORANGE BARLEY 1.5L 2021-12-11 00:00:00+00:00       147.0        BGXA   \n",
       "1     TONIC PET 500ML 2021-12-13 00:00:00+00:00       484.0        VN7V   \n",
       "2       CREAM SODA 1L 2021-12-13 00:00:00+00:00       484.0        VN7V   \n",
       "3    GINGER BEER 1.5L 2021-12-10 00:00:00+00:00   1000053.0        VT9C   \n",
       "4    GINGER BEER 1.5L 2021-12-10 00:00:00+00:00   1000057.0        8QLS   \n",
       "\n",
       "   shop_id  item_price  quantity_sold  shop_area_sq_ft shop_profile  sales  \\\n",
       "0  SHOP008         220              2              678     Moderate    440   \n",
       "1  SHOP008         160              2              678     Moderate    320   \n",
       "2  SHOP008         150              2              678     Moderate    300   \n",
       "3  SHOP008         220              1              678     Moderate    220   \n",
       "4  SHOP008         440              1              678     Moderate    440   \n",
       "\n",
       "   month  day_of_week_0  day_of_week_1  day_of_week_2  day_of_week_3  \\\n",
       "0     12              0              0              0              0   \n",
       "1     12              1              0              0              0   \n",
       "2     12              1              0              0              0   \n",
       "3     12              0              0              0              0   \n",
       "4     12              0              0              0              0   \n",
       "\n",
       "   day_of_week_4  day_of_week_5  day_of_week_6  season_fall  season_winter  \n",
       "0              0              1              0            0              1  \n",
       "1              0              0              0            0              1  \n",
       "2              0              0              0            0              1  \n",
       "3              1              0              0            0              1  \n",
       "4              1              0              0            0              1  "
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "item_description    35928\n",
       "transaction_date        0\n",
       "invoice_id           6320\n",
       "customer_id             0\n",
       "shop_id                 0\n",
       "item_price              0\n",
       "quantity_sold           0\n",
       "shop_area_sq_ft         0\n",
       "shop_profile        86633\n",
       "sales                   0\n",
       "month                   0\n",
       "day_of_week_0           0\n",
       "day_of_week_1           0\n",
       "day_of_week_2           0\n",
       "day_of_week_3           0\n",
       "day_of_week_4           0\n",
       "day_of_week_5           0\n",
       "day_of_week_6           0\n",
       "season_fall             0\n",
       "season_winter           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "caf9b4bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 473974 entries, 0 to 473973\n",
      "Data columns (total 20 columns):\n",
      " #   Column            Non-Null Count   Dtype              \n",
      "---  ------            --------------   -----              \n",
      " 0   item_description  438046 non-null  object             \n",
      " 1   transaction_date  473974 non-null  datetime64[ns, UTC]\n",
      " 2   invoice_id        467654 non-null  float64            \n",
      " 3   customer_id       473974 non-null  object             \n",
      " 4   shop_id           473974 non-null  object             \n",
      " 5   item_price        473974 non-null  int64              \n",
      " 6   quantity_sold     473974 non-null  int64              \n",
      " 7   shop_area_sq_ft   473974 non-null  int64              \n",
      " 8   shop_profile      387341 non-null  object             \n",
      " 9   sales             473974 non-null  int64              \n",
      " 10  month             473974 non-null  int64              \n",
      " 11  day_of_week_0     473974 non-null  uint8              \n",
      " 12  day_of_week_1     473974 non-null  uint8              \n",
      " 13  day_of_week_2     473974 non-null  uint8              \n",
      " 14  day_of_week_3     473974 non-null  uint8              \n",
      " 15  day_of_week_4     473974 non-null  uint8              \n",
      " 16  day_of_week_5     473974 non-null  uint8              \n",
      " 17  day_of_week_6     473974 non-null  uint8              \n",
      " 18  season_fall       473974 non-null  uint8              \n",
      " 19  season_winter     473974 non-null  uint8              \n",
      "dtypes: datetime64[ns, UTC](1), float64(1), int64(5), object(4), uint8(9)\n",
      "memory usage: 47.5+ MB\n"
     ]
    }
   ],
   "source": [
    "merged_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "308acd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming your DataFrame is named 'data'\n",
    "grouped_data = merged_data.groupby('shop_id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "e7aacc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total sales per shop\n",
    "total_sales = grouped_data['sales'].sum()\n",
    "\n",
    "# Average item price per shop\n",
    "average_item_price = grouped_data['item_price'].mean()\n",
    "\n",
    "# Total quantity sold per shop\n",
    "total_quantity_sold = grouped_data['quantity_sold'].sum()\n",
    "\n",
    "# Average sales per day of the week per shop\n",
    "day_of_week_columns = [f'day_of_week_{i}' for i in range(7)]\n",
    "average_sales_day_of_week = grouped_data[day_of_week_columns].mean()\n",
    "\n",
    "# Seasonal sales (fall and winter) per shop\n",
    "season_columns = ['season_fall', 'season_winter']\n",
    "seasonal_sales = grouped_data[season_columns].sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "661b30d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "shops_data = pd.DataFrame({\n",
    "    'total_sales': total_sales,\n",
    "    'average_item_price': average_item_price,\n",
    "    'total_quantity_sold': total_quantity_sold,\n",
    "})\n",
    "shops_data = shops_data.join(average_sales_day_of_week)\n",
    "shops_data = shops_data.join(seasonal_sales)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "27267406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mode shop_profile per shop (using first mode if multiple modes exist)\n",
    "shop_profile_mode = grouped_data['shop_profile'].agg(pd.Series.mode).apply(lambda x: x[0] if isinstance(x, pd.Series) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "590706d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "shops_data = shops_data.join(shop_profile_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "42e444ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 124 entries, SHOP001 to SHOP127\n",
      "Data columns (total 13 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   total_sales          124 non-null    int64  \n",
      " 1   average_item_price   124 non-null    float64\n",
      " 2   total_quantity_sold  124 non-null    int64  \n",
      " 3   day_of_week_0        124 non-null    float64\n",
      " 4   day_of_week_1        124 non-null    float64\n",
      " 5   day_of_week_2        124 non-null    float64\n",
      " 6   day_of_week_3        124 non-null    float64\n",
      " 7   day_of_week_4        124 non-null    float64\n",
      " 8   day_of_week_5        124 non-null    float64\n",
      " 9   day_of_week_6        124 non-null    float64\n",
      " 10  season_fall          124 non-null    float64\n",
      " 11  season_winter        124 non-null    float64\n",
      " 12  shop_profile         124 non-null    object \n",
      "dtypes: float64(10), int64(2), object(1)\n",
      "memory usage: 17.6+ KB\n"
     ]
    }
   ],
   "source": [
    "shops_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "826b1fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate transaction-level data to store-level\n",
    "transaction_features = merged_data.groupby('shop_id').agg({\n",
    "    'month': 'mean',\n",
    "    'day_of_week_0': 'sum',\n",
    "    'day_of_week_1': 'sum',\n",
    "    'day_of_week_2': 'sum',\n",
    "    'day_of_week_3': 'sum',\n",
    "    'day_of_week_4': 'sum',\n",
    "    'day_of_week_5': 'sum',\n",
    "    'day_of_week_6': 'sum',\n",
    "    'season_fall': 'sum',\n",
    "    'season_winter': 'sum',\n",
    "}).reset_index()\n",
    "\n",
    "# Merge aggregated transaction-level features into store-level DataFrame\n",
    "store_profile_data = store_profile_data.merge(transaction_features, on='shop_id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "bd15e469",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_description</th>\n",
       "      <th>transaction_date</th>\n",
       "      <th>invoice_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_price</th>\n",
       "      <th>quantity_sold</th>\n",
       "      <th>shop_area_sq_ft</th>\n",
       "      <th>shop_profile</th>\n",
       "      <th>sales</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week_0</th>\n",
       "      <th>day_of_week_1</th>\n",
       "      <th>day_of_week_2</th>\n",
       "      <th>day_of_week_3</th>\n",
       "      <th>day_of_week_4</th>\n",
       "      <th>day_of_week_5</th>\n",
       "      <th>day_of_week_6</th>\n",
       "      <th>season_fall</th>\n",
       "      <th>season_winter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ORANGE BARLEY 1.5L</td>\n",
       "      <td>2021-12-11 00:00:00+00:00</td>\n",
       "      <td>147.0</td>\n",
       "      <td>BGXA</td>\n",
       "      <td>SHOP008</td>\n",
       "      <td>220</td>\n",
       "      <td>2</td>\n",
       "      <td>678</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>440</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TONIC PET 500ML</td>\n",
       "      <td>2021-12-13 00:00:00+00:00</td>\n",
       "      <td>484.0</td>\n",
       "      <td>VN7V</td>\n",
       "      <td>SHOP008</td>\n",
       "      <td>160</td>\n",
       "      <td>2</td>\n",
       "      <td>678</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>320</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CREAM SODA 1L</td>\n",
       "      <td>2021-12-13 00:00:00+00:00</td>\n",
       "      <td>484.0</td>\n",
       "      <td>VN7V</td>\n",
       "      <td>SHOP008</td>\n",
       "      <td>150</td>\n",
       "      <td>2</td>\n",
       "      <td>678</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>300</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GINGER BEER 1.5L</td>\n",
       "      <td>2021-12-10 00:00:00+00:00</td>\n",
       "      <td>1000053.0</td>\n",
       "      <td>VT9C</td>\n",
       "      <td>SHOP008</td>\n",
       "      <td>220</td>\n",
       "      <td>1</td>\n",
       "      <td>678</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>220</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GINGER BEER 1.5L</td>\n",
       "      <td>2021-12-10 00:00:00+00:00</td>\n",
       "      <td>1000057.0</td>\n",
       "      <td>8QLS</td>\n",
       "      <td>SHOP008</td>\n",
       "      <td>440</td>\n",
       "      <td>1</td>\n",
       "      <td>678</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>440</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     item_description          transaction_date  invoice_id customer_id  \\\n",
       "0  ORANGE BARLEY 1.5L 2021-12-11 00:00:00+00:00       147.0        BGXA   \n",
       "1     TONIC PET 500ML 2021-12-13 00:00:00+00:00       484.0        VN7V   \n",
       "2       CREAM SODA 1L 2021-12-13 00:00:00+00:00       484.0        VN7V   \n",
       "3    GINGER BEER 1.5L 2021-12-10 00:00:00+00:00   1000053.0        VT9C   \n",
       "4    GINGER BEER 1.5L 2021-12-10 00:00:00+00:00   1000057.0        8QLS   \n",
       "\n",
       "   shop_id  item_price  quantity_sold  shop_area_sq_ft shop_profile  sales  \\\n",
       "0  SHOP008         220              2              678     Moderate    440   \n",
       "1  SHOP008         160              2              678     Moderate    320   \n",
       "2  SHOP008         150              2              678     Moderate    300   \n",
       "3  SHOP008         220              1              678     Moderate    220   \n",
       "4  SHOP008         440              1              678     Moderate    440   \n",
       "\n",
       "   month  day_of_week_0  day_of_week_1  day_of_week_2  day_of_week_3  \\\n",
       "0     12              0              0              0              0   \n",
       "1     12              1              0              0              0   \n",
       "2     12              1              0              0              0   \n",
       "3     12              0              0              0              0   \n",
       "4     12              0              0              0              0   \n",
       "\n",
       "   day_of_week_4  day_of_week_5  day_of_week_6  season_fall  season_winter  \n",
       "0              0              1              0            0              1  \n",
       "1              0              0              0            0              1  \n",
       "2              0              0              0            0              1  \n",
       "3              1              0              0            0              1  \n",
       "4              1              0              0            0              1  "
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "9edb67de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 124 entries, 0 to 123\n",
      "Data columns (total 29 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   shop_id                 124 non-null    object \n",
      " 1   shop_area_sq_ft         124 non-null    int64  \n",
      " 2   shop_profile            100 non-null    object \n",
      " 3   total_sales             124 non-null    int64  \n",
      " 4   transaction_count       124 non-null    int64  \n",
      " 5   unique_customers        124 non-null    int64  \n",
      " 6   avg_transaction_value   124 non-null    float64\n",
      " 7   avg_sales_per_customer  124 non-null    float64\n",
      " 8   sales_per_sq_ft         124 non-null    float64\n",
      " 9   month_x                 124 non-null    float64\n",
      " 10  day_of_week_0_x         124 non-null    float64\n",
      " 11  day_of_week_1_x         124 non-null    float64\n",
      " 12  day_of_week_2_x         124 non-null    float64\n",
      " 13  day_of_week_3_x         124 non-null    float64\n",
      " 14  day_of_week_4_x         124 non-null    float64\n",
      " 15  day_of_week_5_x         124 non-null    float64\n",
      " 16  day_of_week_6_x         124 non-null    float64\n",
      " 17  season_fall_x           124 non-null    float64\n",
      " 18  season_winter_x         124 non-null    float64\n",
      " 19  month_y                 124 non-null    float64\n",
      " 20  day_of_week_0_y         124 non-null    float64\n",
      " 21  day_of_week_1_y         124 non-null    float64\n",
      " 22  day_of_week_2_y         124 non-null    float64\n",
      " 23  day_of_week_3_y         124 non-null    float64\n",
      " 24  day_of_week_4_y         124 non-null    float64\n",
      " 25  day_of_week_5_y         124 non-null    float64\n",
      " 26  day_of_week_6_y         124 non-null    float64\n",
      " 27  season_fall_y           124 non-null    float64\n",
      " 28  season_winter_y         124 non-null    float64\n",
      "dtypes: float64(23), int64(4), object(2)\n",
      "memory usage: 29.1+ KB\n"
     ]
    }
   ],
   "source": [
    "store_profile_data.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3533354e",
   "metadata": {},
   "source": [
    "Neural Network Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "97604e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "a1a45e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the input features by scaling them\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "11349217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the labels into integers\n",
    "encoder = LabelEncoder()\n",
    "y_train_encoded = encoder.fit_transform(y_train)\n",
    "y_test_encoded = encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "643842e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the neural network model\n",
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu', input_dim=X_train_scaled.shape[1]))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(len(encoder.classes_), activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "1aa7a4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "10f849c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "13/13 [==============================] - 1s 24ms/step - loss: 1.4445 - accuracy: 0.1919 - val_loss: 1.3978 - val_accuracy: 0.3200\n",
      "Epoch 2/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.3987 - accuracy: 0.2828 - val_loss: 1.3834 - val_accuracy: 0.2800\n",
      "Epoch 3/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.3808 - accuracy: 0.3030 - val_loss: 1.3721 - val_accuracy: 0.3200\n",
      "Epoch 4/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.3834 - accuracy: 0.3030 - val_loss: 1.3588 - val_accuracy: 0.4400\n",
      "Epoch 5/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.3397 - accuracy: 0.3838 - val_loss: 1.3454 - val_accuracy: 0.4400\n",
      "Epoch 6/500\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 1.3304 - accuracy: 0.3434 - val_loss: 1.3360 - val_accuracy: 0.4800\n",
      "Epoch 7/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.3096 - accuracy: 0.2929 - val_loss: 1.3258 - val_accuracy: 0.5600\n",
      "Epoch 8/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.2768 - accuracy: 0.4040 - val_loss: 1.3174 - val_accuracy: 0.5200\n",
      "Epoch 9/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.2921 - accuracy: 0.4444 - val_loss: 1.3111 - val_accuracy: 0.5200\n",
      "Epoch 10/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.2972 - accuracy: 0.3838 - val_loss: 1.3078 - val_accuracy: 0.5200\n",
      "Epoch 11/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.2811 - accuracy: 0.4848 - val_loss: 1.3058 - val_accuracy: 0.4800\n",
      "Epoch 12/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.2733 - accuracy: 0.4444 - val_loss: 1.2996 - val_accuracy: 0.4400\n",
      "Epoch 13/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.2495 - accuracy: 0.4848 - val_loss: 1.2981 - val_accuracy: 0.4400\n",
      "Epoch 14/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.2712 - accuracy: 0.4343 - val_loss: 1.2908 - val_accuracy: 0.4800\n",
      "Epoch 15/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.2642 - accuracy: 0.4040 - val_loss: 1.2841 - val_accuracy: 0.4800\n",
      "Epoch 16/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.2282 - accuracy: 0.4747 - val_loss: 1.2759 - val_accuracy: 0.5200\n",
      "Epoch 17/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.2235 - accuracy: 0.4949 - val_loss: 1.2729 - val_accuracy: 0.4800\n",
      "Epoch 18/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.2085 - accuracy: 0.4545 - val_loss: 1.2715 - val_accuracy: 0.4800\n",
      "Epoch 19/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.2488 - accuracy: 0.4444 - val_loss: 1.2709 - val_accuracy: 0.4800\n",
      "Epoch 20/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.2038 - accuracy: 0.4747 - val_loss: 1.2657 - val_accuracy: 0.4800\n",
      "Epoch 21/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.2016 - accuracy: 0.4949 - val_loss: 1.2615 - val_accuracy: 0.4800\n",
      "Epoch 22/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.2052 - accuracy: 0.4747 - val_loss: 1.2592 - val_accuracy: 0.4800\n",
      "Epoch 23/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.1969 - accuracy: 0.4949 - val_loss: 1.2588 - val_accuracy: 0.4800\n",
      "Epoch 24/500\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.1967 - accuracy: 0.4848 - val_loss: 1.2586 - val_accuracy: 0.4800\n",
      "Epoch 25/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.2110 - accuracy: 0.4646 - val_loss: 1.2523 - val_accuracy: 0.4800\n",
      "Epoch 26/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.1461 - accuracy: 0.4848 - val_loss: 1.2452 - val_accuracy: 0.4800\n",
      "Epoch 27/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.1745 - accuracy: 0.5354 - val_loss: 1.2401 - val_accuracy: 0.4800\n",
      "Epoch 28/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.1121 - accuracy: 0.5455 - val_loss: 1.2365 - val_accuracy: 0.5200\n",
      "Epoch 29/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.1269 - accuracy: 0.5354 - val_loss: 1.2330 - val_accuracy: 0.4800\n",
      "Epoch 30/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.1991 - accuracy: 0.4848 - val_loss: 1.2288 - val_accuracy: 0.4800\n",
      "Epoch 31/500\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 1.1699 - accuracy: 0.4949 - val_loss: 1.2252 - val_accuracy: 0.4800\n",
      "Epoch 32/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.1299 - accuracy: 0.5051 - val_loss: 1.2227 - val_accuracy: 0.4800\n",
      "Epoch 33/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.1718 - accuracy: 0.4545 - val_loss: 1.2208 - val_accuracy: 0.4400\n",
      "Epoch 34/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.1432 - accuracy: 0.5152 - val_loss: 1.2166 - val_accuracy: 0.4400\n",
      "Epoch 35/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.1238 - accuracy: 0.4949 - val_loss: 1.2114 - val_accuracy: 0.4800\n",
      "Epoch 36/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.0608 - accuracy: 0.5657 - val_loss: 1.2055 - val_accuracy: 0.5200\n",
      "Epoch 37/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.1265 - accuracy: 0.5253 - val_loss: 1.2010 - val_accuracy: 0.5200\n",
      "Epoch 38/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.0780 - accuracy: 0.5455 - val_loss: 1.1955 - val_accuracy: 0.5200\n",
      "Epoch 39/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.1088 - accuracy: 0.5556 - val_loss: 1.1945 - val_accuracy: 0.5200\n",
      "Epoch 40/500\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 1.1319 - accuracy: 0.4747 - val_loss: 1.1909 - val_accuracy: 0.5200\n",
      "Epoch 41/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.1067 - accuracy: 0.5354 - val_loss: 1.1865 - val_accuracy: 0.5200\n",
      "Epoch 42/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.0813 - accuracy: 0.5556 - val_loss: 1.1906 - val_accuracy: 0.5200\n",
      "Epoch 43/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.1172 - accuracy: 0.5556 - val_loss: 1.1806 - val_accuracy: 0.5200\n",
      "Epoch 44/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.0532 - accuracy: 0.5758 - val_loss: 1.1764 - val_accuracy: 0.5200\n",
      "Epoch 45/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.0914 - accuracy: 0.5556 - val_loss: 1.1727 - val_accuracy: 0.4800\n",
      "Epoch 46/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.0971 - accuracy: 0.5455 - val_loss: 1.1690 - val_accuracy: 0.4800\n",
      "Epoch 47/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.1071 - accuracy: 0.4949 - val_loss: 1.1679 - val_accuracy: 0.5200\n",
      "Epoch 48/500\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 1.0436 - accuracy: 0.5960 - val_loss: 1.1651 - val_accuracy: 0.5600\n",
      "Epoch 49/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.0856 - accuracy: 0.5354 - val_loss: 1.1591 - val_accuracy: 0.5600\n",
      "Epoch 50/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.0306 - accuracy: 0.6162 - val_loss: 1.1540 - val_accuracy: 0.5600\n",
      "Epoch 51/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.0510 - accuracy: 0.5253 - val_loss: 1.1460 - val_accuracy: 0.6000\n",
      "Epoch 52/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.0623 - accuracy: 0.5556 - val_loss: 1.1516 - val_accuracy: 0.5600\n",
      "Epoch 53/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.0453 - accuracy: 0.5556 - val_loss: 1.1499 - val_accuracy: 0.6000\n",
      "Epoch 54/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.0546 - accuracy: 0.5859 - val_loss: 1.1488 - val_accuracy: 0.6000\n",
      "Epoch 55/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.0575 - accuracy: 0.5657 - val_loss: 1.1568 - val_accuracy: 0.6000\n",
      "Epoch 56/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.0486 - accuracy: 0.5051 - val_loss: 1.1549 - val_accuracy: 0.6000\n",
      "Epoch 57/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.0237 - accuracy: 0.5556 - val_loss: 1.1558 - val_accuracy: 0.5600\n",
      "Epoch 58/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.0558 - accuracy: 0.5354 - val_loss: 1.1512 - val_accuracy: 0.5600\n",
      "Epoch 59/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.0591 - accuracy: 0.5354 - val_loss: 1.1506 - val_accuracy: 0.6000\n",
      "Epoch 60/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.0170 - accuracy: 0.5556 - val_loss: 1.1440 - val_accuracy: 0.5600\n",
      "Epoch 61/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.9860 - accuracy: 0.5758 - val_loss: 1.1450 - val_accuracy: 0.5600\n",
      "Epoch 62/500\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 1.0850 - accuracy: 0.5354 - val_loss: 1.1410 - val_accuracy: 0.5600\n",
      "Epoch 63/500\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 1.0432 - accuracy: 0.5354 - val_loss: 1.1388 - val_accuracy: 0.6000\n",
      "Epoch 64/500\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 1.0604 - accuracy: 0.5354 - val_loss: 1.1415 - val_accuracy: 0.6000\n",
      "Epoch 65/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.0194 - accuracy: 0.5960 - val_loss: 1.1396 - val_accuracy: 0.5600\n",
      "Epoch 66/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.0465 - accuracy: 0.5354 - val_loss: 1.1391 - val_accuracy: 0.5600\n",
      "Epoch 67/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.0247 - accuracy: 0.5253 - val_loss: 1.1351 - val_accuracy: 0.6000\n",
      "Epoch 68/500\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 1.0320 - accuracy: 0.5354 - val_loss: 1.1358 - val_accuracy: 0.5600\n",
      "Epoch 69/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.0136 - accuracy: 0.5960 - val_loss: 1.1407 - val_accuracy: 0.6400\n",
      "Epoch 70/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.0640 - accuracy: 0.5253 - val_loss: 1.1522 - val_accuracy: 0.6000\n",
      "Epoch 71/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.0293 - accuracy: 0.5960 - val_loss: 1.1512 - val_accuracy: 0.6000\n",
      "Epoch 72/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.0372 - accuracy: 0.5253 - val_loss: 1.1564 - val_accuracy: 0.6000\n",
      "Epoch 73/500\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 1.0323 - accuracy: 0.5051 - val_loss: 1.1569 - val_accuracy: 0.6000\n",
      "Epoch 74/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.0769 - accuracy: 0.5152 - val_loss: 1.1589 - val_accuracy: 0.6000\n",
      "Epoch 75/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.0263 - accuracy: 0.5253 - val_loss: 1.1548 - val_accuracy: 0.6000\n",
      "Epoch 76/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.9940 - accuracy: 0.5657 - val_loss: 1.1580 - val_accuracy: 0.6000\n",
      "Epoch 77/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.9844 - accuracy: 0.5960 - val_loss: 1.1567 - val_accuracy: 0.5200\n",
      "Epoch 78/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.0232 - accuracy: 0.5354 - val_loss: 1.1580 - val_accuracy: 0.5600\n",
      "Epoch 79/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.9924 - accuracy: 0.5152 - val_loss: 1.1584 - val_accuracy: 0.5600\n",
      "Epoch 80/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.0294 - accuracy: 0.5657 - val_loss: 1.1554 - val_accuracy: 0.5600\n",
      "Epoch 81/500\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 1.0103 - accuracy: 0.5859 - val_loss: 1.1533 - val_accuracy: 0.5600\n",
      "Epoch 82/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.9469 - accuracy: 0.6364 - val_loss: 1.1527 - val_accuracy: 0.5200\n",
      "Epoch 83/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.9356 - accuracy: 0.6061 - val_loss: 1.1525 - val_accuracy: 0.5600\n",
      "Epoch 84/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.9812 - accuracy: 0.6162 - val_loss: 1.1456 - val_accuracy: 0.5600\n",
      "Epoch 85/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.0002 - accuracy: 0.5455 - val_loss: 1.1521 - val_accuracy: 0.5200\n",
      "Epoch 86/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.0106 - accuracy: 0.5253 - val_loss: 1.1622 - val_accuracy: 0.4800\n",
      "Epoch 87/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.0089 - accuracy: 0.5859 - val_loss: 1.1671 - val_accuracy: 0.5600\n",
      "Epoch 88/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.0166 - accuracy: 0.5556 - val_loss: 1.1595 - val_accuracy: 0.4800\n",
      "Epoch 89/500\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 1.0463 - accuracy: 0.5455 - val_loss: 1.1581 - val_accuracy: 0.4400\n",
      "Epoch 90/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.0144 - accuracy: 0.5152 - val_loss: 1.1640 - val_accuracy: 0.4400\n",
      "Epoch 91/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.9746 - accuracy: 0.5657 - val_loss: 1.1538 - val_accuracy: 0.4400\n",
      "Epoch 92/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.0196 - accuracy: 0.4949 - val_loss: 1.1536 - val_accuracy: 0.4400\n",
      "Epoch 93/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.9956 - accuracy: 0.5556 - val_loss: 1.1609 - val_accuracy: 0.5200\n",
      "Epoch 94/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.9523 - accuracy: 0.5960 - val_loss: 1.1616 - val_accuracy: 0.5200\n",
      "Epoch 95/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.9742 - accuracy: 0.5556 - val_loss: 1.1616 - val_accuracy: 0.5200\n",
      "Epoch 96/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.9993 - accuracy: 0.5455 - val_loss: 1.1605 - val_accuracy: 0.5200\n",
      "Epoch 97/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.9932 - accuracy: 0.5657 - val_loss: 1.1628 - val_accuracy: 0.5200\n",
      "Epoch 98/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.0143 - accuracy: 0.5455 - val_loss: 1.1617 - val_accuracy: 0.4800\n",
      "Epoch 99/500\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.9789 - accuracy: 0.5657 - val_loss: 1.1612 - val_accuracy: 0.4800\n",
      "Epoch 100/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.9384 - accuracy: 0.5960 - val_loss: 1.1554 - val_accuracy: 0.5200\n",
      "Epoch 101/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.0250 - accuracy: 0.4646 - val_loss: 1.1593 - val_accuracy: 0.4800\n",
      "Epoch 102/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.9721 - accuracy: 0.5354 - val_loss: 1.1637 - val_accuracy: 0.4400\n",
      "Epoch 103/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.0203 - accuracy: 0.5253 - val_loss: 1.1627 - val_accuracy: 0.4400\n",
      "Epoch 104/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.9218 - accuracy: 0.5960 - val_loss: 1.1566 - val_accuracy: 0.4800\n",
      "Epoch 105/500\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.9716 - accuracy: 0.6061 - val_loss: 1.1535 - val_accuracy: 0.4800\n",
      "Epoch 106/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.9456 - accuracy: 0.6263 - val_loss: 1.1458 - val_accuracy: 0.4800\n",
      "Epoch 107/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.0134 - accuracy: 0.5253 - val_loss: 1.1482 - val_accuracy: 0.4800\n",
      "Epoch 108/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.9416 - accuracy: 0.5758 - val_loss: 1.1516 - val_accuracy: 0.4800\n",
      "Epoch 109/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.9876 - accuracy: 0.5455 - val_loss: 1.1520 - val_accuracy: 0.4800\n",
      "Epoch 110/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.9621 - accuracy: 0.6667 - val_loss: 1.1581 - val_accuracy: 0.5200\n",
      "Epoch 111/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.9473 - accuracy: 0.6465 - val_loss: 1.1594 - val_accuracy: 0.5200\n",
      "Epoch 112/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.9611 - accuracy: 0.5556 - val_loss: 1.1565 - val_accuracy: 0.5200\n",
      "Epoch 113/500\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.9701 - accuracy: 0.5960 - val_loss: 1.1560 - val_accuracy: 0.5200\n",
      "Epoch 114/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.9782 - accuracy: 0.5960 - val_loss: 1.1662 - val_accuracy: 0.5200\n",
      "Epoch 115/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.9925 - accuracy: 0.5354 - val_loss: 1.1659 - val_accuracy: 0.5200\n",
      "Epoch 116/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.9593 - accuracy: 0.5758 - val_loss: 1.1697 - val_accuracy: 0.5200\n",
      "Epoch 117/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.9175 - accuracy: 0.6061 - val_loss: 1.1690 - val_accuracy: 0.4800\n",
      "Epoch 118/500\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.9627 - accuracy: 0.5960 - val_loss: 1.1638 - val_accuracy: 0.4800\n",
      "Epoch 119/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.9372 - accuracy: 0.6162 - val_loss: 1.1601 - val_accuracy: 0.5200\n",
      "Epoch 120/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.9894 - accuracy: 0.5859 - val_loss: 1.1620 - val_accuracy: 0.5600\n",
      "Epoch 121/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.9770 - accuracy: 0.5859 - val_loss: 1.1744 - val_accuracy: 0.5200\n",
      "Epoch 122/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.9758 - accuracy: 0.5657 - val_loss: 1.1735 - val_accuracy: 0.5200\n",
      "Epoch 123/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.9830 - accuracy: 0.5859 - val_loss: 1.1742 - val_accuracy: 0.4800\n",
      "Epoch 124/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.9603 - accuracy: 0.5354 - val_loss: 1.1697 - val_accuracy: 0.4800\n",
      "Epoch 125/500\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.9304 - accuracy: 0.5960 - val_loss: 1.1752 - val_accuracy: 0.4800\n",
      "Epoch 126/500\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.9163 - accuracy: 0.5556 - val_loss: 1.1732 - val_accuracy: 0.4800\n",
      "Epoch 127/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.9380 - accuracy: 0.5758 - val_loss: 1.1797 - val_accuracy: 0.4800\n",
      "Epoch 128/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.9325 - accuracy: 0.5859 - val_loss: 1.1797 - val_accuracy: 0.5200\n",
      "Epoch 129/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.9269 - accuracy: 0.5758 - val_loss: 1.1832 - val_accuracy: 0.5200\n",
      "Epoch 130/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.9549 - accuracy: 0.6061 - val_loss: 1.1758 - val_accuracy: 0.5200\n",
      "Epoch 131/500\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.8968 - accuracy: 0.6162 - val_loss: 1.1718 - val_accuracy: 0.5600\n",
      "Epoch 132/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.9568 - accuracy: 0.6162 - val_loss: 1.1641 - val_accuracy: 0.5200\n",
      "Epoch 133/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.9920 - accuracy: 0.5354 - val_loss: 1.1648 - val_accuracy: 0.4400\n",
      "Epoch 134/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.9255 - accuracy: 0.6364 - val_loss: 1.1643 - val_accuracy: 0.4800\n",
      "Epoch 135/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.9527 - accuracy: 0.5960 - val_loss: 1.1661 - val_accuracy: 0.4400\n",
      "Epoch 136/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.9498 - accuracy: 0.5455 - val_loss: 1.1808 - val_accuracy: 0.4800\n",
      "Epoch 137/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8859 - accuracy: 0.6364 - val_loss: 1.1774 - val_accuracy: 0.4800\n",
      "Epoch 138/500\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.9539 - accuracy: 0.5253 - val_loss: 1.1789 - val_accuracy: 0.4400\n",
      "Epoch 139/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.9600 - accuracy: 0.5859 - val_loss: 1.1753 - val_accuracy: 0.4800\n",
      "Epoch 140/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.9562 - accuracy: 0.5152 - val_loss: 1.1799 - val_accuracy: 0.4800\n",
      "Epoch 141/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.9552 - accuracy: 0.5960 - val_loss: 1.1787 - val_accuracy: 0.4400\n",
      "Epoch 142/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.9539 - accuracy: 0.5859 - val_loss: 1.1744 - val_accuracy: 0.4400\n",
      "Epoch 143/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.9587 - accuracy: 0.5960 - val_loss: 1.1725 - val_accuracy: 0.4400\n",
      "Epoch 144/500\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.9442 - accuracy: 0.5556 - val_loss: 1.1714 - val_accuracy: 0.4800\n",
      "Epoch 145/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.9346 - accuracy: 0.5859 - val_loss: 1.1767 - val_accuracy: 0.4800\n",
      "Epoch 146/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.9196 - accuracy: 0.6162 - val_loss: 1.1816 - val_accuracy: 0.4400\n",
      "Epoch 147/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.9130 - accuracy: 0.5859 - val_loss: 1.1738 - val_accuracy: 0.4400\n",
      "Epoch 148/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.9358 - accuracy: 0.5556 - val_loss: 1.1806 - val_accuracy: 0.4800\n",
      "Epoch 149/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8795 - accuracy: 0.5960 - val_loss: 1.1766 - val_accuracy: 0.4800\n",
      "Epoch 150/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.9171 - accuracy: 0.6263 - val_loss: 1.1778 - val_accuracy: 0.4800\n",
      "Epoch 151/500\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.9522 - accuracy: 0.5859 - val_loss: 1.1776 - val_accuracy: 0.4800\n",
      "Epoch 152/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.9442 - accuracy: 0.6667 - val_loss: 1.1829 - val_accuracy: 0.4400\n",
      "Epoch 153/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.9075 - accuracy: 0.6263 - val_loss: 1.1869 - val_accuracy: 0.4800\n",
      "Epoch 154/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.9306 - accuracy: 0.5758 - val_loss: 1.1949 - val_accuracy: 0.4400\n",
      "Epoch 155/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.9519 - accuracy: 0.6162 - val_loss: 1.1940 - val_accuracy: 0.4800\n",
      "Epoch 156/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.9343 - accuracy: 0.6263 - val_loss: 1.1974 - val_accuracy: 0.4400\n",
      "Epoch 157/500\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.8996 - accuracy: 0.6061 - val_loss: 1.1931 - val_accuracy: 0.4400\n",
      "Epoch 158/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.8857 - accuracy: 0.6162 - val_loss: 1.1829 - val_accuracy: 0.4800\n",
      "Epoch 159/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8905 - accuracy: 0.6364 - val_loss: 1.1755 - val_accuracy: 0.5200\n",
      "Epoch 160/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.9507 - accuracy: 0.5758 - val_loss: 1.1762 - val_accuracy: 0.5200\n",
      "Epoch 161/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8687 - accuracy: 0.5859 - val_loss: 1.1781 - val_accuracy: 0.4800\n",
      "Epoch 162/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.9340 - accuracy: 0.5960 - val_loss: 1.1842 - val_accuracy: 0.4400\n",
      "Epoch 163/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.9650 - accuracy: 0.5960 - val_loss: 1.1858 - val_accuracy: 0.4800\n",
      "Epoch 164/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.9024 - accuracy: 0.5758 - val_loss: 1.1855 - val_accuracy: 0.4400\n",
      "Epoch 165/500\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.9180 - accuracy: 0.6162 - val_loss: 1.1808 - val_accuracy: 0.4800\n",
      "Epoch 166/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.9316 - accuracy: 0.6263 - val_loss: 1.1780 - val_accuracy: 0.5200\n",
      "Epoch 167/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8726 - accuracy: 0.5960 - val_loss: 1.1831 - val_accuracy: 0.5200\n",
      "Epoch 168/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.9062 - accuracy: 0.5859 - val_loss: 1.1884 - val_accuracy: 0.5200\n",
      "Epoch 169/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.9270 - accuracy: 0.6061 - val_loss: 1.1930 - val_accuracy: 0.5200\n",
      "Epoch 170/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.9316 - accuracy: 0.5758 - val_loss: 1.1987 - val_accuracy: 0.5200\n",
      "Epoch 171/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.8874 - accuracy: 0.6061 - val_loss: 1.1893 - val_accuracy: 0.4400\n",
      "Epoch 172/500\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.9288 - accuracy: 0.6566 - val_loss: 1.1804 - val_accuracy: 0.4800\n",
      "Epoch 173/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.9068 - accuracy: 0.6566 - val_loss: 1.1716 - val_accuracy: 0.5200\n",
      "Epoch 174/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.9288 - accuracy: 0.5556 - val_loss: 1.1651 - val_accuracy: 0.5200\n",
      "Epoch 175/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.9337 - accuracy: 0.5960 - val_loss: 1.1759 - val_accuracy: 0.5200\n",
      "Epoch 176/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.9140 - accuracy: 0.6364 - val_loss: 1.1851 - val_accuracy: 0.5200\n",
      "Epoch 177/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8585 - accuracy: 0.6263 - val_loss: 1.1838 - val_accuracy: 0.5200\n",
      "Epoch 178/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.9395 - accuracy: 0.5859 - val_loss: 1.1883 - val_accuracy: 0.4800\n",
      "Epoch 179/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.9089 - accuracy: 0.5758 - val_loss: 1.1842 - val_accuracy: 0.4400\n",
      "Epoch 180/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.9214 - accuracy: 0.5758 - val_loss: 1.1857 - val_accuracy: 0.4800\n",
      "Epoch 181/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.9142 - accuracy: 0.6061 - val_loss: 1.1907 - val_accuracy: 0.4800\n",
      "Epoch 182/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.9494 - accuracy: 0.5960 - val_loss: 1.1815 - val_accuracy: 0.4400\n",
      "Epoch 183/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.9190 - accuracy: 0.6364 - val_loss: 1.1819 - val_accuracy: 0.5600\n",
      "Epoch 184/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8920 - accuracy: 0.6364 - val_loss: 1.1814 - val_accuracy: 0.5600\n",
      "Epoch 185/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8323 - accuracy: 0.6364 - val_loss: 1.1763 - val_accuracy: 0.5200\n",
      "Epoch 186/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8527 - accuracy: 0.6364 - val_loss: 1.1765 - val_accuracy: 0.5200\n",
      "Epoch 187/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8843 - accuracy: 0.6162 - val_loss: 1.1803 - val_accuracy: 0.4400\n",
      "Epoch 188/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.9118 - accuracy: 0.6061 - val_loss: 1.1878 - val_accuracy: 0.4400\n",
      "Epoch 189/500\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.8640 - accuracy: 0.6061 - val_loss: 1.1897 - val_accuracy: 0.4400\n",
      "Epoch 190/500\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.8823 - accuracy: 0.6364 - val_loss: 1.1876 - val_accuracy: 0.4400\n",
      "Epoch 191/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.9173 - accuracy: 0.5657 - val_loss: 1.1861 - val_accuracy: 0.4400\n",
      "Epoch 192/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.9381 - accuracy: 0.5758 - val_loss: 1.1924 - val_accuracy: 0.4400\n",
      "Epoch 193/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.8661 - accuracy: 0.6263 - val_loss: 1.1950 - val_accuracy: 0.4800\n",
      "Epoch 194/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.8779 - accuracy: 0.6465 - val_loss: 1.1966 - val_accuracy: 0.4400\n",
      "Epoch 195/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.8821 - accuracy: 0.6263 - val_loss: 1.2048 - val_accuracy: 0.4400\n",
      "Epoch 196/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.8744 - accuracy: 0.6263 - val_loss: 1.2089 - val_accuracy: 0.4800\n",
      "Epoch 197/500\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.8821 - accuracy: 0.5960 - val_loss: 1.2048 - val_accuracy: 0.4400\n",
      "Epoch 198/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.8761 - accuracy: 0.5960 - val_loss: 1.1991 - val_accuracy: 0.4800\n",
      "Epoch 199/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.9499 - accuracy: 0.5556 - val_loss: 1.1983 - val_accuracy: 0.4800\n",
      "Epoch 200/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.8661 - accuracy: 0.6465 - val_loss: 1.2080 - val_accuracy: 0.4400\n",
      "Epoch 201/500\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.9062 - accuracy: 0.6162 - val_loss: 1.1999 - val_accuracy: 0.4400\n",
      "Epoch 202/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.8221 - accuracy: 0.6162 - val_loss: 1.2110 - val_accuracy: 0.4400\n",
      "Epoch 203/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8307 - accuracy: 0.6263 - val_loss: 1.2101 - val_accuracy: 0.4400\n",
      "Epoch 204/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8877 - accuracy: 0.5859 - val_loss: 1.2109 - val_accuracy: 0.4400\n",
      "Epoch 205/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.9086 - accuracy: 0.5556 - val_loss: 1.2137 - val_accuracy: 0.4400\n",
      "Epoch 206/500\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.8867 - accuracy: 0.5859 - val_loss: 1.2217 - val_accuracy: 0.4400\n",
      "Epoch 207/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8536 - accuracy: 0.6162 - val_loss: 1.2299 - val_accuracy: 0.4000\n",
      "Epoch 208/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.9135 - accuracy: 0.6364 - val_loss: 1.2351 - val_accuracy: 0.4000\n",
      "Epoch 209/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8449 - accuracy: 0.6263 - val_loss: 1.2321 - val_accuracy: 0.4800\n",
      "Epoch 210/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.9810 - accuracy: 0.5556 - val_loss: 1.2228 - val_accuracy: 0.4400\n",
      "Epoch 211/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8874 - accuracy: 0.6364 - val_loss: 1.2244 - val_accuracy: 0.4000\n",
      "Epoch 212/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8512 - accuracy: 0.6162 - val_loss: 1.2259 - val_accuracy: 0.4000\n",
      "Epoch 213/500\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.8617 - accuracy: 0.5960 - val_loss: 1.2234 - val_accuracy: 0.4000\n",
      "Epoch 214/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8822 - accuracy: 0.5859 - val_loss: 1.2126 - val_accuracy: 0.4000\n",
      "Epoch 215/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8724 - accuracy: 0.6263 - val_loss: 1.2081 - val_accuracy: 0.4400\n",
      "Epoch 216/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8597 - accuracy: 0.6263 - val_loss: 1.2155 - val_accuracy: 0.4400\n",
      "Epoch 217/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8771 - accuracy: 0.6566 - val_loss: 1.2202 - val_accuracy: 0.4400\n",
      "Epoch 218/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8785 - accuracy: 0.6263 - val_loss: 1.2186 - val_accuracy: 0.4400\n",
      "Epoch 219/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8498 - accuracy: 0.5758 - val_loss: 1.2089 - val_accuracy: 0.4400\n",
      "Epoch 220/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8673 - accuracy: 0.6162 - val_loss: 1.2052 - val_accuracy: 0.4800\n",
      "Epoch 221/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.8821 - accuracy: 0.5758 - val_loss: 1.2030 - val_accuracy: 0.4800\n",
      "Epoch 222/500\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.8255 - accuracy: 0.6465 - val_loss: 1.2018 - val_accuracy: 0.4800\n",
      "Epoch 223/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.8761 - accuracy: 0.5960 - val_loss: 1.2023 - val_accuracy: 0.4400\n",
      "Epoch 224/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.9213 - accuracy: 0.5960 - val_loss: 1.1944 - val_accuracy: 0.4400\n",
      "Epoch 225/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8582 - accuracy: 0.6162 - val_loss: 1.1915 - val_accuracy: 0.4400\n",
      "Epoch 226/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8080 - accuracy: 0.6566 - val_loss: 1.1913 - val_accuracy: 0.4800\n",
      "Epoch 227/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8914 - accuracy: 0.6364 - val_loss: 1.1945 - val_accuracy: 0.4800\n",
      "Epoch 228/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8438 - accuracy: 0.6263 - val_loss: 1.1969 - val_accuracy: 0.4800\n",
      "Epoch 229/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8998 - accuracy: 0.5758 - val_loss: 1.1881 - val_accuracy: 0.4400\n",
      "Epoch 230/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8698 - accuracy: 0.5960 - val_loss: 1.1980 - val_accuracy: 0.4400\n",
      "Epoch 231/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8804 - accuracy: 0.6061 - val_loss: 1.2002 - val_accuracy: 0.4400\n",
      "Epoch 232/500\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.8001 - accuracy: 0.6667 - val_loss: 1.2062 - val_accuracy: 0.4400\n",
      "Epoch 233/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8420 - accuracy: 0.6465 - val_loss: 1.2243 - val_accuracy: 0.4800\n",
      "Epoch 234/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8791 - accuracy: 0.6768 - val_loss: 1.2351 - val_accuracy: 0.4400\n",
      "Epoch 235/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8827 - accuracy: 0.6364 - val_loss: 1.2451 - val_accuracy: 0.4400\n",
      "Epoch 236/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.9129 - accuracy: 0.5657 - val_loss: 1.2414 - val_accuracy: 0.4400\n",
      "Epoch 237/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8860 - accuracy: 0.6768 - val_loss: 1.2412 - val_accuracy: 0.4400\n",
      "Epoch 238/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8248 - accuracy: 0.6768 - val_loss: 1.2327 - val_accuracy: 0.4400\n",
      "Epoch 239/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8555 - accuracy: 0.5960 - val_loss: 1.2241 - val_accuracy: 0.5200\n",
      "Epoch 240/500\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.8285 - accuracy: 0.6263 - val_loss: 1.2209 - val_accuracy: 0.5200\n",
      "Epoch 241/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8980 - accuracy: 0.5859 - val_loss: 1.2168 - val_accuracy: 0.4800\n",
      "Epoch 242/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8670 - accuracy: 0.6263 - val_loss: 1.2061 - val_accuracy: 0.4400\n",
      "Epoch 243/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8810 - accuracy: 0.6162 - val_loss: 1.2106 - val_accuracy: 0.4400\n",
      "Epoch 244/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8277 - accuracy: 0.6263 - val_loss: 1.2148 - val_accuracy: 0.4400\n",
      "Epoch 245/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8247 - accuracy: 0.6263 - val_loss: 1.2172 - val_accuracy: 0.4800\n",
      "Epoch 246/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8864 - accuracy: 0.6061 - val_loss: 1.2156 - val_accuracy: 0.4800\n",
      "Epoch 247/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8017 - accuracy: 0.6566 - val_loss: 1.2084 - val_accuracy: 0.4800\n",
      "Epoch 248/500\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.8467 - accuracy: 0.6162 - val_loss: 1.2113 - val_accuracy: 0.4800\n",
      "Epoch 249/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.9124 - accuracy: 0.6162 - val_loss: 1.2047 - val_accuracy: 0.5200\n",
      "Epoch 250/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8345 - accuracy: 0.6162 - val_loss: 1.2089 - val_accuracy: 0.4800\n",
      "Epoch 251/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8584 - accuracy: 0.6364 - val_loss: 1.2089 - val_accuracy: 0.4800\n",
      "Epoch 252/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8623 - accuracy: 0.6162 - val_loss: 1.2083 - val_accuracy: 0.4800\n",
      "Epoch 253/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8416 - accuracy: 0.6061 - val_loss: 1.2091 - val_accuracy: 0.4400\n",
      "Epoch 254/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.8395 - accuracy: 0.6465 - val_loss: 1.2084 - val_accuracy: 0.4400\n",
      "Epoch 255/500\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.8531 - accuracy: 0.6566 - val_loss: 1.2141 - val_accuracy: 0.4400\n",
      "Epoch 256/500\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.8286 - accuracy: 0.6768 - val_loss: 1.2231 - val_accuracy: 0.4400\n",
      "Epoch 257/500\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.8509 - accuracy: 0.6465 - val_loss: 1.2249 - val_accuracy: 0.4000\n",
      "Epoch 258/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7924 - accuracy: 0.6667 - val_loss: 1.2213 - val_accuracy: 0.4000\n",
      "Epoch 259/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.8426 - accuracy: 0.6667 - val_loss: 1.2308 - val_accuracy: 0.4400\n",
      "Epoch 260/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.8182 - accuracy: 0.6566 - val_loss: 1.2408 - val_accuracy: 0.4400\n",
      "Epoch 261/500\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.8484 - accuracy: 0.5960 - val_loss: 1.2529 - val_accuracy: 0.4400\n",
      "Epoch 262/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.9090 - accuracy: 0.6162 - val_loss: 1.2464 - val_accuracy: 0.4400\n",
      "Epoch 263/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7953 - accuracy: 0.6364 - val_loss: 1.2364 - val_accuracy: 0.4400\n",
      "Epoch 264/500\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.8042 - accuracy: 0.6566 - val_loss: 1.2304 - val_accuracy: 0.4800\n",
      "Epoch 265/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.8659 - accuracy: 0.6263 - val_loss: 1.2341 - val_accuracy: 0.4400\n",
      "Epoch 266/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.8583 - accuracy: 0.6566 - val_loss: 1.2418 - val_accuracy: 0.4400\n",
      "Epoch 267/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.9284 - accuracy: 0.5960 - val_loss: 1.2408 - val_accuracy: 0.4000\n",
      "Epoch 268/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.8929 - accuracy: 0.5859 - val_loss: 1.2321 - val_accuracy: 0.4000\n",
      "Epoch 269/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.8631 - accuracy: 0.6364 - val_loss: 1.2231 - val_accuracy: 0.4400\n",
      "Epoch 270/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.8660 - accuracy: 0.5960 - val_loss: 1.2170 - val_accuracy: 0.4800\n",
      "Epoch 271/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8600 - accuracy: 0.6263 - val_loss: 1.2163 - val_accuracy: 0.4400\n",
      "Epoch 272/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.7925 - accuracy: 0.6768 - val_loss: 1.2255 - val_accuracy: 0.4800\n",
      "Epoch 273/500\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.8987 - accuracy: 0.6162 - val_loss: 1.2419 - val_accuracy: 0.4400\n",
      "Epoch 274/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8799 - accuracy: 0.6061 - val_loss: 1.2261 - val_accuracy: 0.5200\n",
      "Epoch 275/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.8825 - accuracy: 0.5859 - val_loss: 1.2291 - val_accuracy: 0.4800\n",
      "Epoch 276/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.8024 - accuracy: 0.6869 - val_loss: 1.2359 - val_accuracy: 0.4000\n",
      "Epoch 277/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.8062 - accuracy: 0.6566 - val_loss: 1.2440 - val_accuracy: 0.3600\n",
      "Epoch 278/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.8847 - accuracy: 0.6162 - val_loss: 1.2389 - val_accuracy: 0.4000\n",
      "Epoch 279/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.8558 - accuracy: 0.6162 - val_loss: 1.2329 - val_accuracy: 0.4400\n",
      "Epoch 280/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.8485 - accuracy: 0.6162 - val_loss: 1.2230 - val_accuracy: 0.4800\n",
      "Epoch 281/500\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.8053 - accuracy: 0.6465 - val_loss: 1.2153 - val_accuracy: 0.5200\n",
      "Epoch 282/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.8849 - accuracy: 0.6162 - val_loss: 1.2230 - val_accuracy: 0.4800\n",
      "Epoch 283/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7978 - accuracy: 0.6465 - val_loss: 1.2228 - val_accuracy: 0.4800\n",
      "Epoch 284/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.8041 - accuracy: 0.6364 - val_loss: 1.2208 - val_accuracy: 0.4400\n",
      "Epoch 285/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.7982 - accuracy: 0.6364 - val_loss: 1.2314 - val_accuracy: 0.4400\n",
      "Epoch 286/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.9122 - accuracy: 0.6566 - val_loss: 1.2265 - val_accuracy: 0.4400\n",
      "Epoch 287/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.8153 - accuracy: 0.6061 - val_loss: 1.2277 - val_accuracy: 0.4400\n",
      "Epoch 288/500\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.8037 - accuracy: 0.6667 - val_loss: 1.2324 - val_accuracy: 0.4400\n",
      "Epoch 289/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.8317 - accuracy: 0.6465 - val_loss: 1.2361 - val_accuracy: 0.4400\n",
      "Epoch 290/500\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.8184 - accuracy: 0.6465 - val_loss: 1.2390 - val_accuracy: 0.4400\n",
      "Epoch 291/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7570 - accuracy: 0.6566 - val_loss: 1.2479 - val_accuracy: 0.4800\n",
      "Epoch 292/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.8383 - accuracy: 0.6364 - val_loss: 1.2509 - val_accuracy: 0.4800\n",
      "Epoch 293/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.8315 - accuracy: 0.6768 - val_loss: 1.2494 - val_accuracy: 0.4400\n",
      "Epoch 294/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.9121 - accuracy: 0.6162 - val_loss: 1.2579 - val_accuracy: 0.4400\n",
      "Epoch 295/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.8873 - accuracy: 0.5859 - val_loss: 1.2546 - val_accuracy: 0.4400\n",
      "Epoch 296/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.9125 - accuracy: 0.5960 - val_loss: 1.2521 - val_accuracy: 0.4800\n",
      "Epoch 297/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.8706 - accuracy: 0.6667 - val_loss: 1.2576 - val_accuracy: 0.5200\n",
      "Epoch 298/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.8086 - accuracy: 0.6364 - val_loss: 1.2449 - val_accuracy: 0.5600\n",
      "Epoch 299/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.8385 - accuracy: 0.6162 - val_loss: 1.2350 - val_accuracy: 0.5600\n",
      "Epoch 300/500\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.7551 - accuracy: 0.6768 - val_loss: 1.2213 - val_accuracy: 0.5200\n",
      "Epoch 301/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.8567 - accuracy: 0.6667 - val_loss: 1.2302 - val_accuracy: 0.4800\n",
      "Epoch 302/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.8030 - accuracy: 0.6869 - val_loss: 1.2495 - val_accuracy: 0.4800\n",
      "Epoch 303/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.8149 - accuracy: 0.6465 - val_loss: 1.2468 - val_accuracy: 0.4800\n",
      "Epoch 304/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8612 - accuracy: 0.5960 - val_loss: 1.2484 - val_accuracy: 0.4800\n",
      "Epoch 305/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8278 - accuracy: 0.6263 - val_loss: 1.2461 - val_accuracy: 0.4800\n",
      "Epoch 306/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7987 - accuracy: 0.6566 - val_loss: 1.2448 - val_accuracy: 0.4800\n",
      "Epoch 307/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8248 - accuracy: 0.6566 - val_loss: 1.2464 - val_accuracy: 0.4400\n",
      "Epoch 308/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8464 - accuracy: 0.6263 - val_loss: 1.2546 - val_accuracy: 0.4400\n",
      "Epoch 309/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7674 - accuracy: 0.6869 - val_loss: 1.2708 - val_accuracy: 0.4400\n",
      "Epoch 310/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8056 - accuracy: 0.6364 - val_loss: 1.2825 - val_accuracy: 0.4400\n",
      "Epoch 311/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7636 - accuracy: 0.6364 - val_loss: 1.2972 - val_accuracy: 0.4400\n",
      "Epoch 312/500\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.7948 - accuracy: 0.6465 - val_loss: 1.2885 - val_accuracy: 0.4400\n",
      "Epoch 313/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7746 - accuracy: 0.6465 - val_loss: 1.2745 - val_accuracy: 0.4800\n",
      "Epoch 314/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.8512 - accuracy: 0.6364 - val_loss: 1.2812 - val_accuracy: 0.4800\n",
      "Epoch 315/500\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.8267 - accuracy: 0.6364 - val_loss: 1.2955 - val_accuracy: 0.5200\n",
      "Epoch 316/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.7996 - accuracy: 0.6667 - val_loss: 1.2800 - val_accuracy: 0.5200\n",
      "Epoch 317/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.8324 - accuracy: 0.6768 - val_loss: 1.2609 - val_accuracy: 0.5200\n",
      "Epoch 318/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7976 - accuracy: 0.6364 - val_loss: 1.2727 - val_accuracy: 0.5200\n",
      "Epoch 319/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.8304 - accuracy: 0.6768 - val_loss: 1.2781 - val_accuracy: 0.4800\n",
      "Epoch 320/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8478 - accuracy: 0.6061 - val_loss: 1.2726 - val_accuracy: 0.4800\n",
      "Epoch 321/500\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.8720 - accuracy: 0.5859 - val_loss: 1.2681 - val_accuracy: 0.5200\n",
      "Epoch 322/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.8009 - accuracy: 0.6869 - val_loss: 1.2712 - val_accuracy: 0.4800\n",
      "Epoch 323/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.8092 - accuracy: 0.6667 - val_loss: 1.2852 - val_accuracy: 0.4800\n",
      "Epoch 324/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7742 - accuracy: 0.6970 - val_loss: 1.2900 - val_accuracy: 0.4400\n",
      "Epoch 325/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7965 - accuracy: 0.6566 - val_loss: 1.2879 - val_accuracy: 0.4800\n",
      "Epoch 326/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.8103 - accuracy: 0.6162 - val_loss: 1.2925 - val_accuracy: 0.4800\n",
      "Epoch 327/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8589 - accuracy: 0.5657 - val_loss: 1.2880 - val_accuracy: 0.4400\n",
      "Epoch 328/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7450 - accuracy: 0.6566 - val_loss: 1.2703 - val_accuracy: 0.4400\n",
      "Epoch 329/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.8585 - accuracy: 0.6061 - val_loss: 1.2720 - val_accuracy: 0.4800\n",
      "Epoch 330/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8039 - accuracy: 0.6364 - val_loss: 1.2663 - val_accuracy: 0.4800\n",
      "Epoch 331/500\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.8232 - accuracy: 0.6263 - val_loss: 1.2660 - val_accuracy: 0.4800\n",
      "Epoch 332/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8097 - accuracy: 0.6667 - val_loss: 1.2689 - val_accuracy: 0.4800\n",
      "Epoch 333/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7792 - accuracy: 0.6364 - val_loss: 1.2760 - val_accuracy: 0.4400\n",
      "Epoch 334/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8119 - accuracy: 0.7071 - val_loss: 1.2912 - val_accuracy: 0.4400\n",
      "Epoch 335/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7910 - accuracy: 0.6263 - val_loss: 1.3033 - val_accuracy: 0.4400\n",
      "Epoch 336/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7934 - accuracy: 0.7071 - val_loss: 1.2955 - val_accuracy: 0.4400\n",
      "Epoch 337/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7793 - accuracy: 0.6364 - val_loss: 1.2937 - val_accuracy: 0.4400\n",
      "Epoch 338/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8062 - accuracy: 0.6364 - val_loss: 1.2783 - val_accuracy: 0.4800\n",
      "Epoch 339/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8304 - accuracy: 0.6162 - val_loss: 1.2611 - val_accuracy: 0.4800\n",
      "Epoch 340/500\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.8185 - accuracy: 0.6263 - val_loss: 1.2751 - val_accuracy: 0.4400\n",
      "Epoch 341/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7963 - accuracy: 0.6263 - val_loss: 1.2845 - val_accuracy: 0.4400\n",
      "Epoch 342/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.8404 - accuracy: 0.6162 - val_loss: 1.2951 - val_accuracy: 0.4400\n",
      "Epoch 343/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7388 - accuracy: 0.6566 - val_loss: 1.3154 - val_accuracy: 0.4400\n",
      "Epoch 344/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8125 - accuracy: 0.6162 - val_loss: 1.3204 - val_accuracy: 0.4400\n",
      "Epoch 345/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7189 - accuracy: 0.7273 - val_loss: 1.3037 - val_accuracy: 0.4400\n",
      "Epoch 346/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7758 - accuracy: 0.6768 - val_loss: 1.3212 - val_accuracy: 0.4400\n",
      "Epoch 347/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8351 - accuracy: 0.6364 - val_loss: 1.3060 - val_accuracy: 0.4400\n",
      "Epoch 348/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7924 - accuracy: 0.6768 - val_loss: 1.2899 - val_accuracy: 0.4400\n",
      "Epoch 349/500\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.7735 - accuracy: 0.6970 - val_loss: 1.2815 - val_accuracy: 0.4400\n",
      "Epoch 350/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7382 - accuracy: 0.6869 - val_loss: 1.2826 - val_accuracy: 0.4800\n",
      "Epoch 351/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7594 - accuracy: 0.6263 - val_loss: 1.2934 - val_accuracy: 0.5600\n",
      "Epoch 352/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7693 - accuracy: 0.6566 - val_loss: 1.2992 - val_accuracy: 0.5600\n",
      "Epoch 353/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7794 - accuracy: 0.6061 - val_loss: 1.3125 - val_accuracy: 0.4800\n",
      "Epoch 354/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8077 - accuracy: 0.6162 - val_loss: 1.3082 - val_accuracy: 0.5200\n",
      "Epoch 355/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.7597 - accuracy: 0.6364 - val_loss: 1.3153 - val_accuracy: 0.5200\n",
      "Epoch 356/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8564 - accuracy: 0.6162 - val_loss: 1.3155 - val_accuracy: 0.5200\n",
      "Epoch 357/500\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.7364 - accuracy: 0.6566 - val_loss: 1.3196 - val_accuracy: 0.4800\n",
      "Epoch 358/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.8102 - accuracy: 0.5960 - val_loss: 1.2991 - val_accuracy: 0.4800\n",
      "Epoch 359/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.8447 - accuracy: 0.6465 - val_loss: 1.3004 - val_accuracy: 0.4800\n",
      "Epoch 360/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.8162 - accuracy: 0.6566 - val_loss: 1.3290 - val_accuracy: 0.4400\n",
      "Epoch 361/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.9005 - accuracy: 0.6465 - val_loss: 1.3257 - val_accuracy: 0.4000\n",
      "Epoch 362/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.7852 - accuracy: 0.6667 - val_loss: 1.3186 - val_accuracy: 0.4400\n",
      "Epoch 363/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7825 - accuracy: 0.6869 - val_loss: 1.3156 - val_accuracy: 0.4400\n",
      "Epoch 364/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7882 - accuracy: 0.6869 - val_loss: 1.3211 - val_accuracy: 0.4400\n",
      "Epoch 365/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7954 - accuracy: 0.7172 - val_loss: 1.3346 - val_accuracy: 0.4400\n",
      "Epoch 366/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7590 - accuracy: 0.6869 - val_loss: 1.3368 - val_accuracy: 0.4400\n",
      "Epoch 367/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7963 - accuracy: 0.6263 - val_loss: 1.3194 - val_accuracy: 0.4400\n",
      "Epoch 368/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.8255 - accuracy: 0.6263 - val_loss: 1.3098 - val_accuracy: 0.4400\n",
      "Epoch 369/500\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.7941 - accuracy: 0.6465 - val_loss: 1.3027 - val_accuracy: 0.4400\n",
      "Epoch 370/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7685 - accuracy: 0.6364 - val_loss: 1.2930 - val_accuracy: 0.4400\n",
      "Epoch 371/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7821 - accuracy: 0.6566 - val_loss: 1.3046 - val_accuracy: 0.4800\n",
      "Epoch 372/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7838 - accuracy: 0.6667 - val_loss: 1.3264 - val_accuracy: 0.4800\n",
      "Epoch 373/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7864 - accuracy: 0.6566 - val_loss: 1.3305 - val_accuracy: 0.4400\n",
      "Epoch 374/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7225 - accuracy: 0.6869 - val_loss: 1.3353 - val_accuracy: 0.4400\n",
      "Epoch 375/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7996 - accuracy: 0.6667 - val_loss: 1.3443 - val_accuracy: 0.4400\n",
      "Epoch 376/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7824 - accuracy: 0.6869 - val_loss: 1.3447 - val_accuracy: 0.4400\n",
      "Epoch 377/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7723 - accuracy: 0.6869 - val_loss: 1.3548 - val_accuracy: 0.4400\n",
      "Epoch 378/500\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.7400 - accuracy: 0.6465 - val_loss: 1.3389 - val_accuracy: 0.4400\n",
      "Epoch 379/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7180 - accuracy: 0.6970 - val_loss: 1.3510 - val_accuracy: 0.4400\n",
      "Epoch 380/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.7763 - accuracy: 0.6566 - val_loss: 1.3639 - val_accuracy: 0.4400\n",
      "Epoch 381/500\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.7852 - accuracy: 0.6667 - val_loss: 1.3384 - val_accuracy: 0.4800\n",
      "Epoch 382/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.8426 - accuracy: 0.6162 - val_loss: 1.3421 - val_accuracy: 0.4400\n",
      "Epoch 383/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.8133 - accuracy: 0.6061 - val_loss: 1.3262 - val_accuracy: 0.4400\n",
      "Epoch 384/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.7643 - accuracy: 0.6566 - val_loss: 1.3164 - val_accuracy: 0.4400\n",
      "Epoch 385/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.7334 - accuracy: 0.6869 - val_loss: 1.3195 - val_accuracy: 0.4400\n",
      "Epoch 386/500\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.8044 - accuracy: 0.6162 - val_loss: 1.3402 - val_accuracy: 0.4400\n",
      "Epoch 387/500\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.7898 - accuracy: 0.6869 - val_loss: 1.3533 - val_accuracy: 0.4400\n",
      "Epoch 388/500\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.8484 - accuracy: 0.6162 - val_loss: 1.3476 - val_accuracy: 0.4400\n",
      "Epoch 389/500\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.7435 - accuracy: 0.6667 - val_loss: 1.3477 - val_accuracy: 0.4400\n",
      "Epoch 390/500\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.7819 - accuracy: 0.6364 - val_loss: 1.3552 - val_accuracy: 0.4400\n",
      "Epoch 391/500\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.7921 - accuracy: 0.6566 - val_loss: 1.3465 - val_accuracy: 0.4400\n",
      "Epoch 392/500\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.8140 - accuracy: 0.6364 - val_loss: 1.3476 - val_accuracy: 0.4400\n",
      "Epoch 393/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7574 - accuracy: 0.6970 - val_loss: 1.3345 - val_accuracy: 0.4800\n",
      "Epoch 394/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7801 - accuracy: 0.6970 - val_loss: 1.3512 - val_accuracy: 0.4800\n",
      "Epoch 395/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7335 - accuracy: 0.6768 - val_loss: 1.3555 - val_accuracy: 0.4400\n",
      "Epoch 396/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7909 - accuracy: 0.6364 - val_loss: 1.3577 - val_accuracy: 0.4400\n",
      "Epoch 397/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7986 - accuracy: 0.6263 - val_loss: 1.3558 - val_accuracy: 0.4800\n",
      "Epoch 398/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7641 - accuracy: 0.6667 - val_loss: 1.3597 - val_accuracy: 0.4800\n",
      "Epoch 399/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7919 - accuracy: 0.6667 - val_loss: 1.3681 - val_accuracy: 0.4400\n",
      "Epoch 400/500\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.8092 - accuracy: 0.6364 - val_loss: 1.3689 - val_accuracy: 0.4400\n",
      "Epoch 401/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8036 - accuracy: 0.6768 - val_loss: 1.3470 - val_accuracy: 0.4400\n",
      "Epoch 402/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7004 - accuracy: 0.6869 - val_loss: 1.3543 - val_accuracy: 0.4400\n",
      "Epoch 403/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7145 - accuracy: 0.6869 - val_loss: 1.3750 - val_accuracy: 0.4000\n",
      "Epoch 404/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7262 - accuracy: 0.6768 - val_loss: 1.3872 - val_accuracy: 0.4000\n",
      "Epoch 405/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7540 - accuracy: 0.6465 - val_loss: 1.3768 - val_accuracy: 0.4400\n",
      "Epoch 406/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7311 - accuracy: 0.7374 - val_loss: 1.3720 - val_accuracy: 0.4800\n",
      "Epoch 407/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7745 - accuracy: 0.6162 - val_loss: 1.3765 - val_accuracy: 0.4400\n",
      "Epoch 408/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7194 - accuracy: 0.6768 - val_loss: 1.3832 - val_accuracy: 0.4400\n",
      "Epoch 409/500\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.7638 - accuracy: 0.6364 - val_loss: 1.3899 - val_accuracy: 0.4800\n",
      "Epoch 410/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7247 - accuracy: 0.6667 - val_loss: 1.3958 - val_accuracy: 0.4400\n",
      "Epoch 411/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7690 - accuracy: 0.6970 - val_loss: 1.3994 - val_accuracy: 0.4400\n",
      "Epoch 412/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7556 - accuracy: 0.6566 - val_loss: 1.3903 - val_accuracy: 0.4800\n",
      "Epoch 413/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7703 - accuracy: 0.6465 - val_loss: 1.3768 - val_accuracy: 0.4800\n",
      "Epoch 414/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7308 - accuracy: 0.6667 - val_loss: 1.4002 - val_accuracy: 0.4800\n",
      "Epoch 415/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.7334 - accuracy: 0.6768 - val_loss: 1.4213 - val_accuracy: 0.4400\n",
      "Epoch 416/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7423 - accuracy: 0.6768 - val_loss: 1.4316 - val_accuracy: 0.4400\n",
      "Epoch 417/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8306 - accuracy: 0.6566 - val_loss: 1.4265 - val_accuracy: 0.4400\n",
      "Epoch 418/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7276 - accuracy: 0.6768 - val_loss: 1.4170 - val_accuracy: 0.4400\n",
      "Epoch 419/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7466 - accuracy: 0.6970 - val_loss: 1.4050 - val_accuracy: 0.4800\n",
      "Epoch 420/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7823 - accuracy: 0.6566 - val_loss: 1.3966 - val_accuracy: 0.4800\n",
      "Epoch 421/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7061 - accuracy: 0.6768 - val_loss: 1.3924 - val_accuracy: 0.4800\n",
      "Epoch 422/500\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.7834 - accuracy: 0.6667 - val_loss: 1.3975 - val_accuracy: 0.4800\n",
      "Epoch 423/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8031 - accuracy: 0.5960 - val_loss: 1.3986 - val_accuracy: 0.4400\n",
      "Epoch 424/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7895 - accuracy: 0.6465 - val_loss: 1.4159 - val_accuracy: 0.4400\n",
      "Epoch 425/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6881 - accuracy: 0.7071 - val_loss: 1.4327 - val_accuracy: 0.4400\n",
      "Epoch 426/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.7394 - accuracy: 0.6768 - val_loss: 1.4359 - val_accuracy: 0.4400\n",
      "Epoch 427/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7326 - accuracy: 0.6667 - val_loss: 1.4314 - val_accuracy: 0.4400\n",
      "Epoch 428/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7448 - accuracy: 0.6465 - val_loss: 1.4480 - val_accuracy: 0.4400\n",
      "Epoch 429/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7538 - accuracy: 0.6869 - val_loss: 1.4588 - val_accuracy: 0.4400\n",
      "Epoch 430/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8225 - accuracy: 0.6162 - val_loss: 1.4561 - val_accuracy: 0.4000\n",
      "Epoch 431/500\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.8023 - accuracy: 0.6869 - val_loss: 1.4338 - val_accuracy: 0.4400\n",
      "Epoch 432/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.8204 - accuracy: 0.6970 - val_loss: 1.4313 - val_accuracy: 0.4800\n",
      "Epoch 433/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6831 - accuracy: 0.7172 - val_loss: 1.4451 - val_accuracy: 0.4400\n",
      "Epoch 434/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7700 - accuracy: 0.6970 - val_loss: 1.4788 - val_accuracy: 0.4400\n",
      "Epoch 435/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7809 - accuracy: 0.6263 - val_loss: 1.4887 - val_accuracy: 0.4400\n",
      "Epoch 436/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7454 - accuracy: 0.6667 - val_loss: 1.4810 - val_accuracy: 0.4000\n",
      "Epoch 437/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7212 - accuracy: 0.6768 - val_loss: 1.4696 - val_accuracy: 0.4000\n",
      "Epoch 438/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7316 - accuracy: 0.6465 - val_loss: 1.4631 - val_accuracy: 0.4000\n",
      "Epoch 439/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7873 - accuracy: 0.6566 - val_loss: 1.4183 - val_accuracy: 0.4800\n",
      "Epoch 440/500\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.6935 - accuracy: 0.6869 - val_loss: 1.4134 - val_accuracy: 0.4800\n",
      "Epoch 441/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7423 - accuracy: 0.6970 - val_loss: 1.4060 - val_accuracy: 0.4400\n",
      "Epoch 442/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.7940 - accuracy: 0.6364 - val_loss: 1.4108 - val_accuracy: 0.4800\n",
      "Epoch 443/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.7822 - accuracy: 0.6263 - val_loss: 1.4015 - val_accuracy: 0.4800\n",
      "Epoch 444/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7218 - accuracy: 0.6970 - val_loss: 1.4121 - val_accuracy: 0.4400\n",
      "Epoch 445/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6797 - accuracy: 0.6869 - val_loss: 1.4214 - val_accuracy: 0.4000\n",
      "Epoch 446/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7319 - accuracy: 0.6465 - val_loss: 1.4149 - val_accuracy: 0.4400\n",
      "Epoch 447/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7295 - accuracy: 0.6667 - val_loss: 1.4247 - val_accuracy: 0.4400\n",
      "Epoch 448/500\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 0.6670 - accuracy: 0.7374 - val_loss: 1.4226 - val_accuracy: 0.4800\n",
      "Epoch 449/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7768 - accuracy: 0.6667 - val_loss: 1.4311 - val_accuracy: 0.4800\n",
      "Epoch 450/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7649 - accuracy: 0.6465 - val_loss: 1.4338 - val_accuracy: 0.4400\n",
      "Epoch 451/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.8324 - accuracy: 0.6465 - val_loss: 1.4166 - val_accuracy: 0.4400\n",
      "Epoch 452/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7690 - accuracy: 0.6667 - val_loss: 1.4125 - val_accuracy: 0.4400\n",
      "Epoch 453/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7183 - accuracy: 0.6667 - val_loss: 1.4365 - val_accuracy: 0.4400\n",
      "Epoch 454/500\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.7689 - accuracy: 0.6869 - val_loss: 1.4278 - val_accuracy: 0.4400\n",
      "Epoch 455/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7953 - accuracy: 0.6667 - val_loss: 1.4076 - val_accuracy: 0.4400\n",
      "Epoch 456/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7037 - accuracy: 0.7071 - val_loss: 1.3944 - val_accuracy: 0.4000\n",
      "Epoch 457/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8308 - accuracy: 0.6263 - val_loss: 1.4213 - val_accuracy: 0.4000\n",
      "Epoch 458/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7373 - accuracy: 0.6970 - val_loss: 1.4194 - val_accuracy: 0.4000\n",
      "Epoch 459/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7413 - accuracy: 0.6970 - val_loss: 1.4043 - val_accuracy: 0.4000\n",
      "Epoch 460/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7372 - accuracy: 0.6768 - val_loss: 1.3920 - val_accuracy: 0.4400\n",
      "Epoch 461/500\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.7046 - accuracy: 0.6869 - val_loss: 1.4034 - val_accuracy: 0.4400\n",
      "Epoch 462/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7293 - accuracy: 0.7071 - val_loss: 1.3855 - val_accuracy: 0.4400\n",
      "Epoch 463/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7705 - accuracy: 0.6768 - val_loss: 1.3678 - val_accuracy: 0.4400\n",
      "Epoch 464/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7556 - accuracy: 0.6667 - val_loss: 1.3576 - val_accuracy: 0.4800\n",
      "Epoch 465/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7745 - accuracy: 0.6465 - val_loss: 1.3676 - val_accuracy: 0.4800\n",
      "Epoch 466/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6988 - accuracy: 0.6970 - val_loss: 1.3982 - val_accuracy: 0.4800\n",
      "Epoch 467/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8033 - accuracy: 0.5859 - val_loss: 1.3950 - val_accuracy: 0.4400\n",
      "Epoch 468/500\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.6834 - accuracy: 0.7374 - val_loss: 1.3799 - val_accuracy: 0.4000\n",
      "Epoch 469/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6999 - accuracy: 0.6566 - val_loss: 1.3982 - val_accuracy: 0.4000\n",
      "Epoch 470/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7159 - accuracy: 0.6364 - val_loss: 1.4086 - val_accuracy: 0.4400\n",
      "Epoch 471/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6993 - accuracy: 0.6768 - val_loss: 1.4410 - val_accuracy: 0.4400\n",
      "Epoch 472/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6833 - accuracy: 0.7172 - val_loss: 1.4661 - val_accuracy: 0.4400\n",
      "Epoch 473/500\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.7412 - accuracy: 0.6061 - val_loss: 1.4700 - val_accuracy: 0.4400\n",
      "Epoch 474/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7525 - accuracy: 0.6970 - val_loss: 1.4558 - val_accuracy: 0.4000\n",
      "Epoch 475/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6934 - accuracy: 0.7374 - val_loss: 1.4528 - val_accuracy: 0.4000\n",
      "Epoch 476/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7100 - accuracy: 0.6566 - val_loss: 1.4474 - val_accuracy: 0.4000\n",
      "Epoch 477/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6916 - accuracy: 0.6970 - val_loss: 1.4558 - val_accuracy: 0.4400\n",
      "Epoch 478/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7100 - accuracy: 0.7273 - val_loss: 1.4765 - val_accuracy: 0.4400\n",
      "Epoch 479/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7636 - accuracy: 0.6465 - val_loss: 1.4586 - val_accuracy: 0.4000\n",
      "Epoch 480/500\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 0.6762 - accuracy: 0.7172 - val_loss: 1.4436 - val_accuracy: 0.4400\n",
      "Epoch 481/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7524 - accuracy: 0.6364 - val_loss: 1.4436 - val_accuracy: 0.4400\n",
      "Epoch 482/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6718 - accuracy: 0.7071 - val_loss: 1.4325 - val_accuracy: 0.4400\n",
      "Epoch 483/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7364 - accuracy: 0.6869 - val_loss: 1.4301 - val_accuracy: 0.4400\n",
      "Epoch 484/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7596 - accuracy: 0.6263 - val_loss: 1.4123 - val_accuracy: 0.4400\n",
      "Epoch 485/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7027 - accuracy: 0.7172 - val_loss: 1.4260 - val_accuracy: 0.4400\n",
      "Epoch 486/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7705 - accuracy: 0.6869 - val_loss: 1.4633 - val_accuracy: 0.4000\n",
      "Epoch 487/500\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.8357 - accuracy: 0.6061 - val_loss: 1.5055 - val_accuracy: 0.4000\n",
      "Epoch 488/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6859 - accuracy: 0.7172 - val_loss: 1.5304 - val_accuracy: 0.4400\n",
      "Epoch 489/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7646 - accuracy: 0.6970 - val_loss: 1.5558 - val_accuracy: 0.4400\n",
      "Epoch 490/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7212 - accuracy: 0.6768 - val_loss: 1.5402 - val_accuracy: 0.4000\n",
      "Epoch 491/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7444 - accuracy: 0.6364 - val_loss: 1.5294 - val_accuracy: 0.4000\n",
      "Epoch 492/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7479 - accuracy: 0.6768 - val_loss: 1.5188 - val_accuracy: 0.4000\n",
      "Epoch 493/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7187 - accuracy: 0.6869 - val_loss: 1.5097 - val_accuracy: 0.4400\n",
      "Epoch 494/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7152 - accuracy: 0.6667 - val_loss: 1.4695 - val_accuracy: 0.4000\n",
      "Epoch 495/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6917 - accuracy: 0.7374 - val_loss: 1.4641 - val_accuracy: 0.4400\n",
      "Epoch 496/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7511 - accuracy: 0.6667 - val_loss: 1.4781 - val_accuracy: 0.4000\n",
      "Epoch 497/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6543 - accuracy: 0.7071 - val_loss: 1.4885 - val_accuracy: 0.4000\n",
      "Epoch 498/500\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.8043 - accuracy: 0.6566 - val_loss: 1.4911 - val_accuracy: 0.4400\n",
      "Epoch 499/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.7504 - accuracy: 0.6869 - val_loss: 1.4936 - val_accuracy: 0.4400\n",
      "Epoch 500/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6252 - accuracy: 0.7374 - val_loss: 1.5001 - val_accuracy: 0.4400\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_train_scaled, y_train_encoded, validation_data=(X_test_scaled, y_test_encoded), epochs=500, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "0a32e1a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 23ms/step - loss: 1.5001 - accuracy: 0.4400\n",
      "Test accuracy: 0.44\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "_, test_accuracy = model.evaluate(X_test_scaled, y_test_encoded)\n",
    "print(\"Test accuracy: {:.2f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b25074b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the weights\n",
    "model.save_weights('./acc0.84/my_checkpoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "063c1cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 124 entries, 0 to 123\n",
      "Data columns (total 9 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   shop_id                 124 non-null    object \n",
      " 1   shop_area_sq_ft         124 non-null    int64  \n",
      " 2   shop_profile            100 non-null    object \n",
      " 3   total_sales             124 non-null    int64  \n",
      " 4   transaction_count       124 non-null    int64  \n",
      " 5   unique_customers        124 non-null    int64  \n",
      " 6   avg_transaction_value   124 non-null    float64\n",
      " 7   avg_sales_per_customer  124 non-null    float64\n",
      " 8   sales_per_sq_ft         124 non-null    float64\n",
      "dtypes: float64(3), int64(4), object(2)\n",
      "memory usage: 9.7+ KB\n"
     ]
    }
   ],
   "source": [
    "store_profile_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "afcb93be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "shop_id                    0\n",
       "shop_area_sq_ft            0\n",
       "shop_profile              24\n",
       "total_sales                0\n",
       "transaction_count          0\n",
       "unique_customers           0\n",
       "avg_transaction_value      0\n",
       "avg_sales_per_customer     0\n",
       "sales_per_sq_ft            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store_profile_data.isna().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "591962f7",
   "metadata": {},
   "source": [
    "Bootstrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "69b020da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def create_bootstrapped_dataset(df, n_samples):\n",
    "    bootstrapped_data = df.sample(n=n_samples, replace=True, random_state=np.random.randint(0, 1e5))\n",
    "    return bootstrapped_data\n",
    "\n",
    "# Create 10 bootstrapped datasets\n",
    "n_bootstraps = 10\n",
    "bootstrapped_datasets = [create_bootstrapped_dataset(store_profile_data, len(store_profile_data)) for _ in range(n_bootstraps)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "2d3aaa38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def create_neural_network(input_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, input_dim=input_dim, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    \n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "800ea2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "def preprocess_data(df, target_col):\n",
    "    X = df.drop(target_col, axis=1)\n",
    "    y = df[target_col]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(y)\n",
    "\n",
    "    y = to_categorical(y)\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    return X_train, X_val, y_train, y_val, le\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "33f56f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df, target_col):\n",
    "    df = df.drop(columns=['shop_id'])  # Drop the shop_id column\n",
    "    X = df.drop(columns=[target_col])\n",
    "    y = df[target_col]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(y)\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "    return X_train, X_val, y_train, y_val, le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "a2c93dbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model 1/10\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits' defined at (most recent call last):\n    File \"c:\\Users\\naham\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\naham\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\naham\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\naham\\AppData\\Roaming\\Python\\Python39\\site-packages\\traitlets\\config\\application.py\", line 1043, in launch_instance\n      app.start()\n    File \"C:\\Users\\naham\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\kernelapp.py\", line 725, in start\n      self.io_loop.start()\n    File \"C:\\Users\\naham\\AppData\\Roaming\\Python\\Python39\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\naham\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"c:\\Users\\naham\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"c:\\Users\\naham\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\naham\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\kernelbase.py\", line 513, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\naham\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\kernelbase.py\", line 502, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\naham\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\kernelbase.py\", line 409, in dispatch_shell\n      await result\n    File \"C:\\Users\\naham\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\naham\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\naham\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\naham\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 2961, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\naham\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 3016, in _run_cell\n      result = runner(coro)\n    File \"C:\\Users\\naham\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\naham\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 3221, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\naham\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 3400, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\naham\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 3460, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\naham\\AppData\\Local\\Temp\\ipykernel_17788\\3809908725.py\", line 10, in <module>\n      model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=50, batch_size=32, verbose=0)\n    File \"c:\\Users\\naham\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\naham\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1685, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Users\\naham\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\naham\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\naham\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\naham\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_step\n      loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"c:\\Users\\naham\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1109, in compute_loss\n      return self.compiled_loss(\n    File \"c:\\Users\\naham\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"c:\\Users\\naham\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\losses.py\", line 142, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"c:\\Users\\naham\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\losses.py\", line 268, in call\n      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"c:\\Users\\naham\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\losses.py\", line 2078, in sparse_categorical_crossentropy\n      return backend.sparse_categorical_crossentropy(\n    File \"c:\\Users\\naham\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\backend.py\", line 5660, in sparse_categorical_crossentropy\n      res = tf.nn.sparse_softmax_cross_entropy_with_logits(\nNode: 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits'\nReceived a label value of 3 which is outside the valid range of [0, 3).  Label values: 1 2 0 3 0 3 0 0 2 0 3 1 2 3 1 2 2 0 0 0 1 0 2 3 2 0 0 1 2 2 1 0\n\t [[{{node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_train_function_142838]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[114], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m X_train, X_val, y_train, y_val, le \u001b[39m=\u001b[39m preprocess_data(bootstrapped_data, target_col\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mshop_profile\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      9\u001b[0m model \u001b[39m=\u001b[39m create_neural_network(input_dim\u001b[39m=\u001b[39mX_train\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m])\n\u001b[1;32m---> 10\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_train, y_train, validation_data\u001b[39m=\u001b[39;49m(X_val, y_val), epochs\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m, verbose\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n\u001b[0;32m     12\u001b[0m ensemble_models\u001b[39m.\u001b[39mappend(model)\n",
      "File \u001b[1;32mc:\\Users\\naham\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\naham\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits' defined at (most recent call last):\n    File \"c:\\Users\\naham\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\naham\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\naham\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\naham\\AppData\\Roaming\\Python\\Python39\\site-packages\\traitlets\\config\\application.py\", line 1043, in launch_instance\n      app.start()\n    File \"C:\\Users\\naham\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\kernelapp.py\", line 725, in start\n      self.io_loop.start()\n    File \"C:\\Users\\naham\\AppData\\Roaming\\Python\\Python39\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\naham\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"c:\\Users\\naham\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"c:\\Users\\naham\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\naham\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\kernelbase.py\", line 513, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\naham\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\kernelbase.py\", line 502, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\naham\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\kernelbase.py\", line 409, in dispatch_shell\n      await result\n    File \"C:\\Users\\naham\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\naham\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\naham\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\naham\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 2961, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\naham\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 3016, in _run_cell\n      result = runner(coro)\n    File \"C:\\Users\\naham\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\naham\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 3221, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\naham\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 3400, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\naham\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 3460, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\naham\\AppData\\Local\\Temp\\ipykernel_17788\\3809908725.py\", line 10, in <module>\n      model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=50, batch_size=32, verbose=0)\n    File \"c:\\Users\\naham\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\naham\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1685, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Users\\naham\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\naham\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\naham\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\naham\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_step\n      loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"c:\\Users\\naham\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1109, in compute_loss\n      return self.compiled_loss(\n    File \"c:\\Users\\naham\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"c:\\Users\\naham\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\losses.py\", line 142, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"c:\\Users\\naham\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\losses.py\", line 268, in call\n      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"c:\\Users\\naham\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\losses.py\", line 2078, in sparse_categorical_crossentropy\n      return backend.sparse_categorical_crossentropy(\n    File \"c:\\Users\\naham\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\backend.py\", line 5660, in sparse_categorical_crossentropy\n      res = tf.nn.sparse_softmax_cross_entropy_with_logits(\nNode: 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits'\nReceived a label value of 3 which is outside the valid range of [0, 3).  Label values: 1 2 0 3 0 3 0 0 2 0 3 1 2 3 1 2 2 0 0 0 1 0 2 3 2 0 0 1 2 2 1 0\n\t [[{{node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_train_function_142838]"
     ]
    }
   ],
   "source": [
    "n_bootstraps = 10\n",
    "ensemble_models = []\n",
    "\n",
    "for i, bootstrapped_data in enumerate(bootstrapped_datasets):\n",
    "    print(f\"Training model {i + 1}/{n_bootstraps}\")\n",
    "\n",
    "    X_train, X_val, y_train, y_val, le = preprocess_data(bootstrapped_data, target_col='shop_profile')\n",
    "\n",
    "    model = create_neural_network(input_dim=X_train.shape[1])\n",
    "    model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=50, batch_size=32, verbose=0)\n",
    "\n",
    "    ensemble_models.append(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0f7d2a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_predictions(models, X):\n",
    "    predictions = []\n",
    "\n",
    "    for model in models:\n",
    "        pred = model.predict(X)\n",
    "        predictions.append(pred)\n",
    "\n",
    "    return np.mean(predictions, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a8cf853f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000270B5F7B700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000270B5F7BE50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       0.65      0.96      0.77        25\n",
      "         Low       0.72      0.72      0.72        29\n",
      "    Moderate       0.86      0.46      0.60        26\n",
      "\n",
      "    accuracy                           0.71        80\n",
      "   macro avg       0.74      0.72      0.70        80\n",
      "weighted avg       0.74      0.71      0.70        80\n",
      "\n",
      "F1 Score: 0.70\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "# Preprocess the original dataset (without bootstrapping)\n",
    "X_test, _, y_test, _, le = preprocess_data(store_profile_data, target_col='shop_profile')\n",
    "\n",
    "# Make predictions using the ensemble\n",
    "predictions = []\n",
    "for model in ensemble_models:\n",
    "    pred = model.predict(X_test)\n",
    "    pred_classes = np.argmax(pred, axis=1)\n",
    "    predictions.append(pred_classes)\n",
    "\n",
    "# Combine predictions from all models (majority vote)\n",
    "ensemble_predictions = np.array(predictions).T\n",
    "final_predictions = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=1, arr=ensemble_predictions)\n",
    "\n",
    "# Evaluate the ensemble\n",
    "print(classification_report(y_test, final_predictions, target_names=le.classes_))\n",
    "f1 = f1_score(y_test, final_predictions, average='weighted')\n",
    "print(f\"F1 Score: {f1:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "871d413e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training SVM and Random Forest 1/10\n",
      "Training SVM and Random Forest 2/10\n",
      "Training SVM and Random Forest 3/10\n",
      "Training SVM and Random Forest 4/10\n",
      "Training SVM and Random Forest 5/10\n",
      "Training SVM and Random Forest 6/10\n",
      "Training SVM and Random Forest 7/10\n",
      "Training SVM and Random Forest 8/10\n",
      "Training SVM and Random Forest 9/10\n",
      "Training SVM and Random Forest 10/10\n",
      "\n",
      "SVM Ensemble:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       0.67      0.80      0.73        25\n",
      "         Low       0.56      0.76      0.65        29\n",
      "    Moderate       0.45      0.19      0.27        26\n",
      "\n",
      "    accuracy                           0.59        80\n",
      "   macro avg       0.56      0.58      0.55        80\n",
      "weighted avg       0.56      0.59      0.55        80\n",
      "\n",
      "F1 Score: 0.55\n",
      "\n",
      "Random Forest Ensemble:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       0.79      0.92      0.85        25\n",
      "         Low       0.79      0.90      0.84        29\n",
      "    Moderate       0.94      0.65      0.77        26\n",
      "\n",
      "    accuracy                           0.82        80\n",
      "   macro avg       0.84      0.82      0.82        80\n",
      "weighted avg       0.84      0.82      0.82        80\n",
      "\n",
      "F1 Score: 0.82\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "n_bootstraps = 10\n",
    "ensemble_models_svm = []\n",
    "ensemble_models_rf = []\n",
    "\n",
    "# Train SVM and Random Forest models on bootstrapped datasets\n",
    "for i, bootstrapped_data in enumerate(bootstrapped_datasets):\n",
    "    print(f\"Training SVM and Random Forest {i + 1}/{n_bootstraps}\")\n",
    "\n",
    "    X_train, X_val, y_train, y_val, le = preprocess_data(bootstrapped_data, target_col='shop_profile')\n",
    "\n",
    "    # Train SVM\n",
    "    svm = SVC(kernel='linear', C=1, probability=True)\n",
    "    svm.fit(X_train, y_train)\n",
    "    ensemble_models_svm.append(svm)\n",
    "\n",
    "    # Train Random Forest\n",
    "    rf = RandomForestClassifier(n_estimators=200, max_depth=None, min_samples_split=2, min_samples_leaf=1)\n",
    "    rf.fit(X_train, y_train)\n",
    "    ensemble_models_rf.append(rf)\n",
    "\n",
    "# Preprocess the original dataset (without bootstrapping)\n",
    "X_test, _, y_test, _, le = preprocess_data(store_profile_data, target_col='shop_profile')\n",
    "\n",
    "# Make predictions using the SVM ensemble\n",
    "predictions_svm = []\n",
    "for model in ensemble_models_svm:\n",
    "    pred = model.predict_proba(X_test)\n",
    "    pred_classes = np.argmax(pred, axis=1)\n",
    "    predictions_svm.append(pred_classes)\n",
    "\n",
    "# Make predictions using the Random Forest ensemble\n",
    "predictions_rf = []\n",
    "for model in ensemble_models_rf:\n",
    "    pred = model.predict_proba(X_test)\n",
    "    pred_classes = np.argmax(pred, axis=1)\n",
    "    predictions_rf.append(pred_classes)\n",
    "\n",
    "# Combine predictions from SVM models (majority vote)\n",
    "ensemble_predictions_svm = np.array(predictions_svm).T\n",
    "final_predictions_svm = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=1, arr=ensemble_predictions_svm)\n",
    "\n",
    "# Combine predictions from Random Forest models (majority vote)\n",
    "ensemble_predictions_rf = np.array(predictions_rf).T\n",
    "final_predictions_rf = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=1, arr=ensemble_predictions_rf)\n",
    "\n",
    "# Evaluate the SVM ensemble\n",
    "print(\"\\nSVM Ensemble:\")\n",
    "print(classification_report(y_test, final_predictions_svm, target_names=le.classes_))\n",
    "f1_svm = f1_score(y_test, final_predictions_svm, average='weighted')\n",
    "print(f\"F1 Score: {f1_svm:.2f}\")\n",
    "\n",
    "# Evaluate the Random Forest ensemble\n",
    "print(\"\\nRandom Forest Ensemble:\")\n",
    "print(classification_report(y_test, final_predictions_rf, target_names=le.classes_))\n",
    "f1_rf = f1_score(y_test, final_predictions_rf, average='weighted')\n",
    "print(f\"F1 Score: {f1_rf:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9db9cec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest Ensemble:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       0.79      0.92      0.85        25\n",
      "         Low       0.79      0.90      0.84        29\n",
      "    Moderate       0.94      0.65      0.77        26\n",
      "\n",
      "    accuracy                           0.82        80\n",
      "   macro avg       0.84      0.82      0.82        80\n",
      "weighted avg       0.84      0.82      0.82        80\n",
      "\n",
      "F1 Score: 0.82\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the Random Forest ensemble\n",
    "print(\"\\nRandom Forest Ensemble:\")\n",
    "print(classification_report(y_test, final_predictions_rf, target_names=le.classes_))\n",
    "f1_rf = f1_score(y_test, final_predictions_rf, average='weighted')\n",
    "print(f\"F1 Score: {f1_rf:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "7a95b042",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "shop_id                    0\n",
       "shop_area_sq_ft            0\n",
       "shop_profile              24\n",
       "total_sales                0\n",
       "transaction_count          0\n",
       "unique_customers           0\n",
       "avg_transaction_value      0\n",
       "avg_sales_per_customer     0\n",
       "sales_per_sq_ft            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store_profile_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "23a40bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df, target_col=None):\n",
    "    df = df.drop(columns=['shop_id'])  # Drop the shop_id column\n",
    "    if target_col is not None:\n",
    "        X = df.drop(columns=[target_col])\n",
    "        y = df[target_col]\n",
    "    else:\n",
    "        X = df\n",
    "        y = None\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "\n",
    "    if y is not None:\n",
    "        le = LabelEncoder()\n",
    "        y = le.fit_transform(y)\n",
    "    else:\n",
    "        le = None\n",
    "\n",
    "    return X, y, scaler, le\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "209c2f54",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 5, got 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[120], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m test_data \u001b[39m=\u001b[39m store_profile_data[store_profile_data[\u001b[39m'\u001b[39m\u001b[39mshop_profile\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39misnull()]\n\u001b[0;32m     10\u001b[0m \u001b[39m# Prepare train dataset for bootstrapping\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m X_train, _, y_train, _, le \u001b[39m=\u001b[39m preprocess_data(train_data, target_col\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mshop_profile\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     13\u001b[0m \u001b[39m# Bootstrapping\u001b[39;00m\n\u001b[0;32m     14\u001b[0m n_bootstraps \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 5, got 4)"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Preprocess the data\n",
    "# Split the dataset into train (with shop profile) and test (missing shop profile) datasets\n",
    "train_data = store_profile_data[store_profile_data['shop_profile'].notnull()]\n",
    "test_data = store_profile_data[store_profile_data['shop_profile'].isnull()]\n",
    "\n",
    "# Prepare train dataset for bootstrapping\n",
    "X_train, _, y_train, _, le = preprocess_data(train_data, target_col='shop_profile')\n",
    "\n",
    "# Bootstrapping\n",
    "n_bootstraps = 10\n",
    "f1_scores = []\n",
    "rf_models = []\n",
    "\n",
    "for i in range(n_bootstraps):\n",
    "    X_train_boot, y_train_boot = resample(X_train, y_train)\n",
    "    rf = RandomForestClassifier(n_estimators=200, max_depth=None, min_samples_split=2, min_samples_leaf=1)\n",
    "    rf.fit(X_train_boot, y_train_boot)\n",
    "    rf_models.append(rf)\n",
    "    \n",
    "    # Evaluate the model on the original train dataset\n",
    "    y_pred = rf.predict(X_train)\n",
    "    f1 = f1_score(y_train, y_pred, average='weighted')\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "# Choose the best model\n",
    "best_rf = rf_models[np.argmax(f1_scores)]\n",
    "\n",
    "# Make predictions on the test dataset\n",
    "X_test, _, _, _, _ = preprocess_data(test_data.drop(columns='shop_profile'), target_col=None)\n",
    "predicted_profiles = best_rf.predict(X_test)\n",
    "\n",
    "# Replace missing shop profile values with the predicted ones\n",
    "test_data['shop_profile'] = le.inverse_transform(predicted_profiles)\n",
    "\n",
    "# Store predicted shop profiles in a separate DataFrame\n",
    "predicted_profiles_df = test_data[['shop_id', 'shop_profile']]\n",
    "\n",
    "print(predicted_profiles_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "96fa5be6",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['shop_profile'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[118], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m test_data \u001b[39m=\u001b[39m test_data\u001b[39m.\u001b[39mmerge(store_profile_data, on\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mshop_id\u001b[39m\u001b[39m'\u001b[39m, how\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mleft\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[39m# Preprocess the testing data\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m X_test, _, _, _ \u001b[39m=\u001b[39m preprocess_data(test_data\u001b[39m.\u001b[39;49mdrop(columns\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mshop_profile\u001b[39;49m\u001b[39m'\u001b[39;49m), target_col\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n\u001b[0;32m     13\u001b[0m \u001b[39m# Make predictions on the test dataset\u001b[39;00m\n\u001b[0;32m     14\u001b[0m predicted_profiles \u001b[39m=\u001b[39m best_rf\u001b[39m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32mc:\\Users\\naham\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\naham\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\frame.py:4906\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4774\u001b[0m \u001b[39m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, allowed_args\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mself\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m   4775\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdrop\u001b[39m(\n\u001b[0;32m   4776\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4783\u001b[0m     errors: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   4784\u001b[0m ):\n\u001b[0;32m   4785\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   4786\u001b[0m \u001b[39m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   4787\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4904\u001b[0m \u001b[39m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   4905\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4906\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mdrop(\n\u001b[0;32m   4907\u001b[0m         labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[0;32m   4908\u001b[0m         axis\u001b[39m=\u001b[39;49maxis,\n\u001b[0;32m   4909\u001b[0m         index\u001b[39m=\u001b[39;49mindex,\n\u001b[0;32m   4910\u001b[0m         columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[0;32m   4911\u001b[0m         level\u001b[39m=\u001b[39;49mlevel,\n\u001b[0;32m   4912\u001b[0m         inplace\u001b[39m=\u001b[39;49minplace,\n\u001b[0;32m   4913\u001b[0m         errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m   4914\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\naham\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\generic.py:4150\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4148\u001b[0m \u001b[39mfor\u001b[39;00m axis, labels \u001b[39min\u001b[39;00m axes\u001b[39m.\u001b[39mitems():\n\u001b[0;32m   4149\u001b[0m     \u001b[39mif\u001b[39;00m labels \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 4150\u001b[0m         obj \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39;49m_drop_axis(labels, axis, level\u001b[39m=\u001b[39;49mlevel, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[0;32m   4152\u001b[0m \u001b[39mif\u001b[39;00m inplace:\n\u001b[0;32m   4153\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32mc:\\Users\\naham\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\generic.py:4185\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[0;32m   4183\u001b[0m         new_axis \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39mdrop(labels, level\u001b[39m=\u001b[39mlevel, errors\u001b[39m=\u001b[39merrors)\n\u001b[0;32m   4184\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 4185\u001b[0m         new_axis \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39;49mdrop(labels, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[0;32m   4186\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreindex(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m{axis_name: new_axis})\n\u001b[0;32m   4188\u001b[0m \u001b[39m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4189\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\naham\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6017\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   6015\u001b[0m \u001b[39mif\u001b[39;00m mask\u001b[39m.\u001b[39many():\n\u001b[0;32m   6016\u001b[0m     \u001b[39mif\u001b[39;00m errors \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m-> 6017\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mlabels[mask]\u001b[39m}\u001b[39;00m\u001b[39m not found in axis\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   6018\u001b[0m     indexer \u001b[39m=\u001b[39m indexer[\u001b[39m~\u001b[39mmask]\n\u001b[0;32m   6019\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['shop_profile'] not found in axis\""
     ]
    }
   ],
   "source": [
    "# Create a DataFrame for the testing data\n",
    "test_data = pd.DataFrame({\n",
    "    'shop_id': ['SHOP046', 'SHOP024', 'SHOP023', 'SHOP097', 'SHOP044', 'SHOP030', 'SHOP038', 'SHOP029', 'SHOP096', 'SHOP092', 'SHOP081', 'SHOP076', 'SHOP080', 'SHOP074', 'SHOP107', 'SHOP108', 'SHOP019', 'SHOP002', 'SHOP114', 'SHOP087', 'SHOP050', 'SHOP061', 'SHOP056', 'SHOP070'],\n",
    "    'shop_profile': [np.nan] * 24\n",
    "})\n",
    "\n",
    "# Merge the testing data with the original dataset to get the other features\n",
    "test_data = test_data.merge(store_profile_data, on='shop_id', how='left')\n",
    "\n",
    "# Preprocess the testing data\n",
    "X_test, _, _, _ = preprocess_data(test_data.drop(columns='shop_profile'), target_col=None)\n",
    "\n",
    "# Make predictions on the test dataset\n",
    "predicted_profiles = best_rf.predict(X_test)\n",
    "\n",
    "# Create a DataFrame with the predicted shop profiles\n",
    "predicted_df = pd.DataFrame({\n",
    "    'shop_id': test_data['shop_id'],\n",
    "    'shop_profile': le.inverse_transform(predicted_profiles)\n",
    "})\n",
    "\n",
    "print(predicted_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "22714605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shop_id</th>\n",
       "      <th>shop_area_sq_ft</th>\n",
       "      <th>shop_profile</th>\n",
       "      <th>total_sales</th>\n",
       "      <th>transaction_count</th>\n",
       "      <th>unique_customers</th>\n",
       "      <th>avg_transaction_value</th>\n",
       "      <th>avg_sales_per_customer</th>\n",
       "      <th>sales_per_sq_ft</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SHOP047</td>\n",
       "      <td>528</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>842960</td>\n",
       "      <td>1687</td>\n",
       "      <td>928</td>\n",
       "      <td>499.679905</td>\n",
       "      <td>908.362069</td>\n",
       "      <td>1596.515152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SHOP009</td>\n",
       "      <td>676</td>\n",
       "      <td>High</td>\n",
       "      <td>1970870</td>\n",
       "      <td>4521</td>\n",
       "      <td>2498</td>\n",
       "      <td>435.936740</td>\n",
       "      <td>788.979183</td>\n",
       "      <td>2915.488166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SHOP083</td>\n",
       "      <td>676</td>\n",
       "      <td>Low</td>\n",
       "      <td>1691985</td>\n",
       "      <td>3583</td>\n",
       "      <td>1900</td>\n",
       "      <td>472.225788</td>\n",
       "      <td>890.518421</td>\n",
       "      <td>2502.936391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SHOP117</td>\n",
       "      <td>676</td>\n",
       "      <td>Low</td>\n",
       "      <td>2325980</td>\n",
       "      <td>4023</td>\n",
       "      <td>2037</td>\n",
       "      <td>578.170520</td>\n",
       "      <td>1141.865488</td>\n",
       "      <td>3440.798817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SHOP042</td>\n",
       "      <td>676</td>\n",
       "      <td>Low</td>\n",
       "      <td>1340215</td>\n",
       "      <td>3232</td>\n",
       "      <td>1841</td>\n",
       "      <td>414.670483</td>\n",
       "      <td>727.982075</td>\n",
       "      <td>1982.566568</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   shop_id  shop_area_sq_ft shop_profile  total_sales  transaction_count  \\\n",
       "0  SHOP047              528     Moderate       842960               1687   \n",
       "1  SHOP009              676         High      1970870               4521   \n",
       "2  SHOP083              676          Low      1691985               3583   \n",
       "3  SHOP117              676          Low      2325980               4023   \n",
       "4  SHOP042              676          Low      1340215               3232   \n",
       "\n",
       "   unique_customers  avg_transaction_value  avg_sales_per_customer  \\\n",
       "0               928             499.679905              908.362069   \n",
       "1              2498             435.936740              788.979183   \n",
       "2              1900             472.225788              890.518421   \n",
       "3              2037             578.170520             1141.865488   \n",
       "4              1841             414.670483              727.982075   \n",
       "\n",
       "   sales_per_sq_ft  \n",
       "0      1596.515152  \n",
       "1      2915.488166  \n",
       "2      2502.936391  \n",
       "3      3440.798817  \n",
       "4      1982.566568  "
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store_profile_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "e0871e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "def bootstrap_samples(data, n_samples):\n",
    "    bootstrapped_datasets = []\n",
    "    for _ in range(n_samples):\n",
    "        bootstrapped_data = resample(data, replace=True, n_samples=len(data), random_state=None)\n",
    "        bootstrapped_datasets.append(bootstrapped_data)\n",
    "    return bootstrapped_datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "4901ea63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model 1/10\n",
      "F1-score: 0.794\n",
      "Training model 2/10\n",
      "F1-score: 0.848\n",
      "Training model 3/10\n",
      "F1-score: 0.948\n",
      "Training model 4/10\n",
      "F1-score: 0.900\n",
      "Training model 5/10\n",
      "F1-score: 0.691\n",
      "Training model 6/10\n",
      "F1-score: 0.950\n",
      "Training model 7/10\n",
      "F1-score: 0.796\n",
      "Training model 8/10\n",
      "F1-score: 0.900\n",
      "Training model 9/10\n",
      "F1-score: 0.852\n",
      "Training model 10/10\n",
      "F1-score: 0.950\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['shop_profile'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[232], line 68\u001b[0m\n\u001b[0;32m     65\u001b[0m test_data \u001b[39m=\u001b[39m test_data\u001b[39m.\u001b[39mmerge(store_profile_data, on\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mshop_id\u001b[39m\u001b[39m'\u001b[39m, how\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mleft\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     67\u001b[0m \u001b[39m# Preprocess the testing data\u001b[39;00m\n\u001b[1;32m---> 68\u001b[0m X_test, _, _, _ \u001b[39m=\u001b[39m preprocess_data(test_data\u001b[39m.\u001b[39;49mdrop(columns\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mshop_profile\u001b[39;49m\u001b[39m'\u001b[39;49m), target_col\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n\u001b[0;32m     70\u001b[0m \u001b[39m# Make predictions on the test dataset\u001b[39;00m\n\u001b[0;32m     71\u001b[0m predicted_profiles \u001b[39m=\u001b[39m best_rf\u001b[39m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32mc:\\Users\\naham\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\naham\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\frame.py:4906\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4774\u001b[0m \u001b[39m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, allowed_args\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mself\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m   4775\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdrop\u001b[39m(\n\u001b[0;32m   4776\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4783\u001b[0m     errors: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   4784\u001b[0m ):\n\u001b[0;32m   4785\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   4786\u001b[0m \u001b[39m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   4787\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4904\u001b[0m \u001b[39m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   4905\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4906\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mdrop(\n\u001b[0;32m   4907\u001b[0m         labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[0;32m   4908\u001b[0m         axis\u001b[39m=\u001b[39;49maxis,\n\u001b[0;32m   4909\u001b[0m         index\u001b[39m=\u001b[39;49mindex,\n\u001b[0;32m   4910\u001b[0m         columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[0;32m   4911\u001b[0m         level\u001b[39m=\u001b[39;49mlevel,\n\u001b[0;32m   4912\u001b[0m         inplace\u001b[39m=\u001b[39;49minplace,\n\u001b[0;32m   4913\u001b[0m         errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m   4914\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\naham\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\generic.py:4150\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4148\u001b[0m \u001b[39mfor\u001b[39;00m axis, labels \u001b[39min\u001b[39;00m axes\u001b[39m.\u001b[39mitems():\n\u001b[0;32m   4149\u001b[0m     \u001b[39mif\u001b[39;00m labels \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 4150\u001b[0m         obj \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39;49m_drop_axis(labels, axis, level\u001b[39m=\u001b[39;49mlevel, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[0;32m   4152\u001b[0m \u001b[39mif\u001b[39;00m inplace:\n\u001b[0;32m   4153\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32mc:\\Users\\naham\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\generic.py:4185\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[0;32m   4183\u001b[0m         new_axis \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39mdrop(labels, level\u001b[39m=\u001b[39mlevel, errors\u001b[39m=\u001b[39merrors)\n\u001b[0;32m   4184\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 4185\u001b[0m         new_axis \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39;49mdrop(labels, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[0;32m   4186\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreindex(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m{axis_name: new_axis})\n\u001b[0;32m   4188\u001b[0m \u001b[39m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4189\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\naham\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6017\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   6015\u001b[0m \u001b[39mif\u001b[39;00m mask\u001b[39m.\u001b[39many():\n\u001b[0;32m   6016\u001b[0m     \u001b[39mif\u001b[39;00m errors \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m-> 6017\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mlabels[mask]\u001b[39m}\u001b[39;00m\u001b[39m not found in axis\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   6018\u001b[0m     indexer \u001b[39m=\u001b[39m indexer[\u001b[39m~\u001b[39mmask]\n\u001b[0;32m   6019\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['shop_profile'] not found in axis\""
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Assuming store_profile_data is already prepared\n",
    "\n",
    "def preprocess_data(df, target_col=None):\n",
    "    df = df.drop(columns=['shop_id'])  # Drop the shop_id column\n",
    "    if target_col is not None:\n",
    "        X = df.drop(columns=[target_col])\n",
    "        y = df[target_col]\n",
    "    else:\n",
    "        X = df\n",
    "        y = None\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "\n",
    "    if y is not None:\n",
    "        le = LabelEncoder()\n",
    "        y = le.fit_transform(y)\n",
    "    else:\n",
    "        le = None\n",
    "\n",
    "    # Split the data into train and validation sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    return X_train, X_val, y_train, y_val, le\n",
    "\n",
    "\n",
    "# Train the random forest model using the bootstrapped datasets\n",
    "n_bootstraps = 10\n",
    "bootstrapped_datasets = bootstrap_samples(store_profile_data, n_samples=n_bootstraps)\n",
    "\n",
    "rf_models = []\n",
    "f1_scores = []\n",
    "\n",
    "for i, bootstrapped_data in enumerate(bootstrapped_datasets):\n",
    "    print(f\"Training model {i + 1}/{n_bootstraps}\")\n",
    "\n",
    "    X_train, X_val, y_train, y_val, le = preprocess_data(bootstrapped_data, target_col='shop_profile')\n",
    "\n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = rf.predict(X_val)\n",
    "\n",
    "    f1 = f1_score(y_val, y_pred, average='weighted')\n",
    "    print(f\"F1-score: {f1:.3f}\")\n",
    "\n",
    "    rf_models.append(rf)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "# Select the best random forest model\n",
    "best_rf = rf_models[np.argmax(f1_scores)]\n",
    "\n",
    "# Create a DataFrame for the testing data\n",
    "test_data = pd.DataFrame({\n",
    "    'shop_id': ['SHOP046', 'SHOP024', 'SHOP023', 'SHOP097', 'SHOP044', 'SHOP030', 'SHOP038', 'SHOP029', 'SHOP096', 'SHOP092', 'SHOP081', 'SHOP076', 'SHOP080', 'SHOP074', 'SHOP107', 'SHOP108', 'SHOP019', 'SHOP002', 'SHOP114', 'SHOP087', 'SHOP050', 'SHOP061', 'SHOP056', 'SHOP070'],\n",
    "    'shop_profile': [np.nan] * 24\n",
    "})\n",
    "\n",
    "# Merge the testing data with the original dataset to get the other features\n",
    "test_data = test_data.merge(store_profile_data, on='shop_id', how='left')\n",
    "\n",
    "# Preprocess the testing data\n",
    "X_test, _, _, _ = preprocess_data(test_data.drop(columns='shop_profile'), target_col=None)\n",
    "\n",
    "# Make predictions on the test dataset\n",
    "predicted_profiles = best_rf.predict(X_test)\n",
    "\n",
    "# Create a DataFrame with the predicted shop profiles\n",
    "predicted_df = pd.DataFrame({\n",
    "    'shop_id': test_data['shop_id'],\n",
    "    'shop_profile': le.inverse_transform(predicted_profiles)\n",
    "})\n",
    "\n",
    "print(predicted_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "f853ee72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model 1/10\n",
      "F1-score: 0.845\n",
      "Training model 2/10\n",
      "F1-score: 0.670\n",
      "Training model 3/10\n",
      "F1-score: 0.654\n",
      "Training model 4/10\n",
      "F1-score: 0.836\n",
      "Training model 5/10\n",
      "F1-score: 0.848\n",
      "Training model 6/10\n",
      "F1-score: 0.848\n",
      "Training model 7/10\n",
      "F1-score: 0.592\n",
      "Training model 8/10\n",
      "F1-score: 0.655\n",
      "Training model 9/10\n",
      "F1-score: 0.718\n",
      "Training model 10/10\n",
      "F1-score: 0.900\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def preprocess_data(df, target_col=None):\n",
    "    df = df.drop(columns=['shop_id'])  # Drop the shop_id column\n",
    "    if target_col is not None:\n",
    "        X = df.drop(columns=[target_col])\n",
    "        y = df[target_col]\n",
    "    else:\n",
    "        X = df\n",
    "        y = None\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "\n",
    "    if y is not None:\n",
    "        le = LabelEncoder()\n",
    "        y = le.fit_transform(y)\n",
    "    else:\n",
    "        le = None\n",
    "\n",
    "    # Split the data into train and validation sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    return X_train, X_val, y_train, y_val, le\n",
    "\n",
    "def bootstrap_samples(data, n_samples):\n",
    "    sample_indices = np.random.randint(0, len(data), (n_samples, len(data)))\n",
    "    samples = [data.iloc[indices] for indices in sample_indices]\n",
    "    return samples\n",
    "\n",
    "# Train the random forest model using the bootstrapped datasets\n",
    "n_bootstraps = 10\n",
    "bootstrapped_datasets = bootstrap_samples(store_profile_data.dropna(), n_samples=n_bootstraps)\n",
    "\n",
    "rf_models = []\n",
    "f1_scores = []\n",
    "\n",
    "for i, bootstrapped_data in enumerate(bootstrapped_datasets):\n",
    "    print(f\"Training model {i + 1}/{n_bootstraps}\")\n",
    "    \n",
    "    X_train, X_val, y_train, y_val, le = preprocess_data(bootstrapped_data, target_col='shop_profile')\n",
    "    \n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    rf.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = rf.predict(X_val)\n",
    "    f1 = f1_score(y_val, y_pred, average='weighted')\n",
    "    print(f\"F1-score: {f1:.3f}\")\n",
    "    \n",
    "    rf_models.append(rf)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "# Choose the best model based on the F1-score\n",
    "best_rf = rf_models[np.argmax(f1_scores)]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "20c456c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(random_state=42)\n"
     ]
    }
   ],
   "source": [
    "print(best_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "d7f8a690",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Find rows with missing shop profiles\n",
    "missing_shop_profiles = store_profile_data[store_profile_data['shop_profile'].isnull()][['shop_id']]\n",
    "\n",
    "# Preprocess the data\n",
    "X_missing = missing_shop_profiles.merge(store_profile_data, on='shop_id', how='left').drop(columns=['shop_id', 'shop_profile'])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_missing = scaler.fit_transform(X_missing)\n",
    "\n",
    "# Make predictions on the test dataset\n",
    "predicted_profiles = best_rf.predict(X_missing)\n",
    "predicted_profiles = le.inverse_transform(predicted_profiles)  # Convert the encoded labels back to the original labels\n",
    "\n",
    "# Replace missing shop profile values with the predicted ones\n",
    "missing_shop_profiles['shop_profile'] = predicted_profiles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "54293cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 24 entries, 100 to 123\n",
      "Data columns (total 2 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   shop_id       24 non-null     object\n",
      " 1   shop_profile  24 non-null     object\n",
      "dtypes: object(2)\n",
      "memory usage: 576.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "missing_shop_profiles.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "9b06e670",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_shop_profiles.to_csv(\"predicted_missing_shop_profiles.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "ed5553b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 1s 37ms/step - loss: 1.1317 - accuracy: 0.3750 - val_loss: 1.0875 - val_accuracy: 0.4000\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.0835 - accuracy: 0.3875 - val_loss: 1.0349 - val_accuracy: 0.4000\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.0434 - accuracy: 0.4125 - val_loss: 0.9933 - val_accuracy: 0.3500\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.0083 - accuracy: 0.5125 - val_loss: 0.9594 - val_accuracy: 0.5500\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9782 - accuracy: 0.6125 - val_loss: 0.9267 - val_accuracy: 0.7500\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.9508 - accuracy: 0.6125 - val_loss: 0.8987 - val_accuracy: 0.8000\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9280 - accuracy: 0.5750 - val_loss: 0.8726 - val_accuracy: 0.8500\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9054 - accuracy: 0.6000 - val_loss: 0.8508 - val_accuracy: 0.7500\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8838 - accuracy: 0.6125 - val_loss: 0.8324 - val_accuracy: 0.7500\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8681 - accuracy: 0.6125 - val_loss: 0.8154 - val_accuracy: 0.7500\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8510 - accuracy: 0.6125 - val_loss: 0.8010 - val_accuracy: 0.7500\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8365 - accuracy: 0.6125 - val_loss: 0.7899 - val_accuracy: 0.7500\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8238 - accuracy: 0.6000 - val_loss: 0.7822 - val_accuracy: 0.7500\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8119 - accuracy: 0.6250 - val_loss: 0.7748 - val_accuracy: 0.7500\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8004 - accuracy: 0.6250 - val_loss: 0.7682 - val_accuracy: 0.7500\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7909 - accuracy: 0.6625 - val_loss: 0.7636 - val_accuracy: 0.7500\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7825 - accuracy: 0.6750 - val_loss: 0.7607 - val_accuracy: 0.7500\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.7729 - accuracy: 0.6875 - val_loss: 0.7591 - val_accuracy: 0.7500\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7645 - accuracy: 0.6625 - val_loss: 0.7611 - val_accuracy: 0.7500\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7567 - accuracy: 0.6625 - val_loss: 0.7633 - val_accuracy: 0.7000\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7481 - accuracy: 0.6500 - val_loss: 0.7653 - val_accuracy: 0.7000\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.7404 - accuracy: 0.6500 - val_loss: 0.7669 - val_accuracy: 0.7000\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.7330 - accuracy: 0.6625 - val_loss: 0.7653 - val_accuracy: 0.7000\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7251 - accuracy: 0.6750 - val_loss: 0.7668 - val_accuracy: 0.6500\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7185 - accuracy: 0.6875 - val_loss: 0.7708 - val_accuracy: 0.6500\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.7123 - accuracy: 0.6750 - val_loss: 0.7749 - val_accuracy: 0.6500\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7047 - accuracy: 0.6750 - val_loss: 0.7765 - val_accuracy: 0.6500\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.6978 - accuracy: 0.6875 - val_loss: 0.7806 - val_accuracy: 0.6000\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.6922 - accuracy: 0.6875 - val_loss: 0.7823 - val_accuracy: 0.6000\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6848 - accuracy: 0.6875 - val_loss: 0.7865 - val_accuracy: 0.6500\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.6792 - accuracy: 0.7000 - val_loss: 0.7903 - val_accuracy: 0.6000\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6722 - accuracy: 0.7000 - val_loss: 0.7986 - val_accuracy: 0.6500\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6678 - accuracy: 0.6625 - val_loss: 0.8065 - val_accuracy: 0.6500\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6600 - accuracy: 0.6625 - val_loss: 0.8121 - val_accuracy: 0.6500\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6548 - accuracy: 0.6750 - val_loss: 0.8175 - val_accuracy: 0.6500\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6496 - accuracy: 0.7125 - val_loss: 0.8219 - val_accuracy: 0.6500\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6442 - accuracy: 0.7250 - val_loss: 0.8293 - val_accuracy: 0.6000\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6379 - accuracy: 0.7250 - val_loss: 0.8323 - val_accuracy: 0.5500\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6331 - accuracy: 0.7125 - val_loss: 0.8389 - val_accuracy: 0.5500\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6296 - accuracy: 0.7000 - val_loss: 0.8446 - val_accuracy: 0.5500\n",
      "Epoch 41/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6222 - accuracy: 0.7000 - val_loss: 0.8569 - val_accuracy: 0.5500\n",
      "Epoch 42/200\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6167 - accuracy: 0.7250 - val_loss: 0.8679 - val_accuracy: 0.6000\n",
      "Epoch 43/200\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6116 - accuracy: 0.7250 - val_loss: 0.8778 - val_accuracy: 0.5500\n",
      "Epoch 44/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6062 - accuracy: 0.7375 - val_loss: 0.8845 - val_accuracy: 0.5500\n",
      "Epoch 45/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6014 - accuracy: 0.7625 - val_loss: 0.8854 - val_accuracy: 0.5500\n",
      "Epoch 46/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.5958 - accuracy: 0.7500 - val_loss: 0.8941 - val_accuracy: 0.5500\n",
      "Epoch 47/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.5905 - accuracy: 0.7625 - val_loss: 0.9015 - val_accuracy: 0.5000\n",
      "Epoch 48/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.5870 - accuracy: 0.7625 - val_loss: 0.9104 - val_accuracy: 0.5000\n",
      "Epoch 49/200\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.5808 - accuracy: 0.7625 - val_loss: 0.9199 - val_accuracy: 0.4500\n",
      "Epoch 50/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.5770 - accuracy: 0.7625 - val_loss: 0.9305 - val_accuracy: 0.4500\n",
      "Epoch 51/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.5734 - accuracy: 0.7625 - val_loss: 0.9415 - val_accuracy: 0.4500\n",
      "Epoch 52/200\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.5685 - accuracy: 0.7625 - val_loss: 0.9454 - val_accuracy: 0.4500\n",
      "Epoch 53/200\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.5638 - accuracy: 0.7625 - val_loss: 0.9565 - val_accuracy: 0.4500\n",
      "Epoch 54/200\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.5598 - accuracy: 0.7750 - val_loss: 0.9681 - val_accuracy: 0.4500\n",
      "Epoch 55/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.5554 - accuracy: 0.7875 - val_loss: 0.9755 - val_accuracy: 0.4500\n",
      "Epoch 56/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.5510 - accuracy: 0.7875 - val_loss: 0.9823 - val_accuracy: 0.4500\n",
      "Epoch 57/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.5470 - accuracy: 0.7875 - val_loss: 0.9891 - val_accuracy: 0.4500\n",
      "Epoch 58/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.5434 - accuracy: 0.7875 - val_loss: 0.9997 - val_accuracy: 0.4500\n",
      "Epoch 59/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.5386 - accuracy: 0.7875 - val_loss: 1.0047 - val_accuracy: 0.4500\n",
      "Epoch 60/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.5345 - accuracy: 0.7750 - val_loss: 1.0124 - val_accuracy: 0.4500\n",
      "Epoch 61/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.5313 - accuracy: 0.7750 - val_loss: 1.0139 - val_accuracy: 0.4500\n",
      "Epoch 62/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.5277 - accuracy: 0.7750 - val_loss: 1.0277 - val_accuracy: 0.5000\n",
      "Epoch 63/200\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.5234 - accuracy: 0.7750 - val_loss: 1.0415 - val_accuracy: 0.5000\n",
      "Epoch 64/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.5189 - accuracy: 0.7625 - val_loss: 1.0482 - val_accuracy: 0.4500\n",
      "Epoch 65/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.5162 - accuracy: 0.7625 - val_loss: 1.0580 - val_accuracy: 0.5000\n",
      "Epoch 66/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.5120 - accuracy: 0.7625 - val_loss: 1.0567 - val_accuracy: 0.5000\n",
      "Epoch 67/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.5084 - accuracy: 0.7750 - val_loss: 1.0673 - val_accuracy: 0.5500\n",
      "Epoch 68/200\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.5056 - accuracy: 0.7750 - val_loss: 1.0730 - val_accuracy: 0.5000\n",
      "Epoch 69/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4997 - accuracy: 0.7750 - val_loss: 1.0868 - val_accuracy: 0.5000\n",
      "Epoch 70/200\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.4963 - accuracy: 0.7750 - val_loss: 1.0847 - val_accuracy: 0.5000\n",
      "Epoch 71/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4923 - accuracy: 0.7875 - val_loss: 1.0954 - val_accuracy: 0.5500\n",
      "Epoch 72/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4897 - accuracy: 0.7750 - val_loss: 1.1057 - val_accuracy: 0.5500\n",
      "Epoch 73/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4861 - accuracy: 0.7875 - val_loss: 1.1179 - val_accuracy: 0.5500\n",
      "Epoch 74/200\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.4829 - accuracy: 0.7875 - val_loss: 1.1258 - val_accuracy: 0.5500\n",
      "Epoch 75/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4789 - accuracy: 0.7875 - val_loss: 1.1296 - val_accuracy: 0.5500\n",
      "Epoch 76/200\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.4761 - accuracy: 0.7875 - val_loss: 1.1317 - val_accuracy: 0.5500\n",
      "Epoch 77/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4725 - accuracy: 0.7875 - val_loss: 1.1353 - val_accuracy: 0.5500\n",
      "Epoch 78/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4691 - accuracy: 0.7875 - val_loss: 1.1472 - val_accuracy: 0.5500\n",
      "Epoch 79/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4665 - accuracy: 0.7875 - val_loss: 1.1578 - val_accuracy: 0.5500\n",
      "Epoch 80/200\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.4627 - accuracy: 0.7875 - val_loss: 1.1668 - val_accuracy: 0.5500\n",
      "Epoch 81/200\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.4612 - accuracy: 0.7875 - val_loss: 1.1830 - val_accuracy: 0.5500\n",
      "Epoch 82/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4582 - accuracy: 0.7875 - val_loss: 1.1796 - val_accuracy: 0.5500\n",
      "Epoch 83/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.4541 - accuracy: 0.7875 - val_loss: 1.1921 - val_accuracy: 0.5500\n",
      "Epoch 84/200\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.4517 - accuracy: 0.8000 - val_loss: 1.2001 - val_accuracy: 0.5500\n",
      "Epoch 85/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4497 - accuracy: 0.8000 - val_loss: 1.1983 - val_accuracy: 0.5500\n",
      "Epoch 86/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4462 - accuracy: 0.8125 - val_loss: 1.2166 - val_accuracy: 0.5500\n",
      "Epoch 87/200\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.4417 - accuracy: 0.8000 - val_loss: 1.2184 - val_accuracy: 0.5500\n",
      "Epoch 88/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4394 - accuracy: 0.8000 - val_loss: 1.2295 - val_accuracy: 0.5500\n",
      "Epoch 89/200\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.4354 - accuracy: 0.8125 - val_loss: 1.2369 - val_accuracy: 0.5500\n",
      "Epoch 90/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4329 - accuracy: 0.8000 - val_loss: 1.2431 - val_accuracy: 0.5500\n",
      "Epoch 91/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4306 - accuracy: 0.8000 - val_loss: 1.2450 - val_accuracy: 0.5500\n",
      "Epoch 92/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4283 - accuracy: 0.8250 - val_loss: 1.2631 - val_accuracy: 0.5500\n",
      "Epoch 93/200\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.4244 - accuracy: 0.8250 - val_loss: 1.2692 - val_accuracy: 0.5500\n",
      "Epoch 94/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4240 - accuracy: 0.8250 - val_loss: 1.2666 - val_accuracy: 0.5500\n",
      "Epoch 95/200\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.4206 - accuracy: 0.8250 - val_loss: 1.2760 - val_accuracy: 0.5500\n",
      "Epoch 96/200\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.4171 - accuracy: 0.8125 - val_loss: 1.2927 - val_accuracy: 0.5500\n",
      "Epoch 97/200\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.4141 - accuracy: 0.8250 - val_loss: 1.2962 - val_accuracy: 0.5500\n",
      "Epoch 98/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4105 - accuracy: 0.8250 - val_loss: 1.3046 - val_accuracy: 0.5500\n",
      "Epoch 99/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4089 - accuracy: 0.8250 - val_loss: 1.3017 - val_accuracy: 0.5500\n",
      "Epoch 100/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4087 - accuracy: 0.8250 - val_loss: 1.3109 - val_accuracy: 0.5500\n",
      "Epoch 101/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4034 - accuracy: 0.8250 - val_loss: 1.3233 - val_accuracy: 0.5500\n",
      "Epoch 102/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4005 - accuracy: 0.8250 - val_loss: 1.3373 - val_accuracy: 0.5500\n",
      "Epoch 103/200\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.3994 - accuracy: 0.8250 - val_loss: 1.3440 - val_accuracy: 0.5500\n",
      "Epoch 104/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.3960 - accuracy: 0.8250 - val_loss: 1.3419 - val_accuracy: 0.5500\n",
      "Epoch 105/200\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.3936 - accuracy: 0.8250 - val_loss: 1.3565 - val_accuracy: 0.5500\n",
      "Epoch 106/200\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.3918 - accuracy: 0.8250 - val_loss: 1.3647 - val_accuracy: 0.5500\n",
      "Epoch 107/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.3889 - accuracy: 0.8250 - val_loss: 1.3696 - val_accuracy: 0.5500\n",
      "Epoch 108/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.3859 - accuracy: 0.8250 - val_loss: 1.3827 - val_accuracy: 0.5500\n",
      "Epoch 109/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.3863 - accuracy: 0.8250 - val_loss: 1.4053 - val_accuracy: 0.5500\n",
      "Epoch 110/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.3820 - accuracy: 0.8250 - val_loss: 1.3984 - val_accuracy: 0.5500\n",
      "Epoch 111/200\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.3798 - accuracy: 0.8250 - val_loss: 1.3939 - val_accuracy: 0.5500\n",
      "Epoch 112/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.3772 - accuracy: 0.8250 - val_loss: 1.4102 - val_accuracy: 0.5500\n",
      "Epoch 113/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.3753 - accuracy: 0.8250 - val_loss: 1.4161 - val_accuracy: 0.5500\n",
      "Epoch 114/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.3712 - accuracy: 0.8250 - val_loss: 1.4258 - val_accuracy: 0.5500\n",
      "Epoch 115/200\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.3681 - accuracy: 0.8375 - val_loss: 1.4251 - val_accuracy: 0.5500\n",
      "Epoch 116/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.3679 - accuracy: 0.8250 - val_loss: 1.4303 - val_accuracy: 0.5500\n",
      "Epoch 117/200\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.3653 - accuracy: 0.8375 - val_loss: 1.4311 - val_accuracy: 0.5500\n",
      "Epoch 118/200\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.3621 - accuracy: 0.8250 - val_loss: 1.4485 - val_accuracy: 0.5500\n",
      "Epoch 119/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.3598 - accuracy: 0.8250 - val_loss: 1.4684 - val_accuracy: 0.5500\n",
      "Epoch 120/200\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.3560 - accuracy: 0.8375 - val_loss: 1.4635 - val_accuracy: 0.5500\n",
      "Epoch 121/200\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.3557 - accuracy: 0.8375 - val_loss: 1.4731 - val_accuracy: 0.5500\n",
      "Epoch 122/200\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.3522 - accuracy: 0.8375 - val_loss: 1.4667 - val_accuracy: 0.5500\n",
      "Epoch 123/200\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.3498 - accuracy: 0.8375 - val_loss: 1.4765 - val_accuracy: 0.5500\n",
      "Epoch 124/200\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.3493 - accuracy: 0.8500 - val_loss: 1.4923 - val_accuracy: 0.5500\n",
      "Epoch 125/200\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.3449 - accuracy: 0.8375 - val_loss: 1.4885 - val_accuracy: 0.5500\n",
      "Epoch 126/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.3428 - accuracy: 0.8500 - val_loss: 1.4992 - val_accuracy: 0.5500\n",
      "Epoch 127/200\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.3402 - accuracy: 0.8500 - val_loss: 1.5104 - val_accuracy: 0.5500\n",
      "Epoch 128/200\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.3380 - accuracy: 0.8625 - val_loss: 1.5190 - val_accuracy: 0.5500\n",
      "Epoch 129/200\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.3353 - accuracy: 0.8625 - val_loss: 1.5112 - val_accuracy: 0.5500\n",
      "Epoch 130/200\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.3339 - accuracy: 0.8750 - val_loss: 1.5258 - val_accuracy: 0.5500\n",
      "Epoch 131/200\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.3327 - accuracy: 0.8625 - val_loss: 1.5367 - val_accuracy: 0.5500\n",
      "Epoch 132/200\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.3296 - accuracy: 0.8750 - val_loss: 1.5380 - val_accuracy: 0.5500\n",
      "Epoch 133/200\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.3280 - accuracy: 0.8750 - val_loss: 1.5330 - val_accuracy: 0.5500\n",
      "Epoch 134/200\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.3247 - accuracy: 0.8750 - val_loss: 1.5556 - val_accuracy: 0.5500\n",
      "Epoch 135/200\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.3213 - accuracy: 0.9000 - val_loss: 1.5526 - val_accuracy: 0.5500\n",
      "Epoch 136/200\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.3210 - accuracy: 0.8875 - val_loss: 1.5637 - val_accuracy: 0.5500\n",
      "Epoch 137/200\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.3171 - accuracy: 0.9000 - val_loss: 1.5674 - val_accuracy: 0.5500\n",
      "Epoch 138/200\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.3148 - accuracy: 0.9000 - val_loss: 1.5722 - val_accuracy: 0.5500\n",
      "Epoch 139/200\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.3127 - accuracy: 0.9000 - val_loss: 1.5722 - val_accuracy: 0.5500\n",
      "Epoch 140/200\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.3126 - accuracy: 0.8875 - val_loss: 1.5937 - val_accuracy: 0.5500\n",
      "Epoch 141/200\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.3099 - accuracy: 0.9000 - val_loss: 1.5895 - val_accuracy: 0.5500\n",
      "Epoch 142/200\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.3078 - accuracy: 0.8875 - val_loss: 1.5906 - val_accuracy: 0.5500\n",
      "Epoch 143/200\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.3044 - accuracy: 0.9000 - val_loss: 1.6089 - val_accuracy: 0.5500\n",
      "Epoch 144/200\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.3019 - accuracy: 0.9125 - val_loss: 1.6223 - val_accuracy: 0.5500\n",
      "Epoch 145/200\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.3002 - accuracy: 0.9125 - val_loss: 1.6139 - val_accuracy: 0.5500\n",
      "Epoch 146/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.2980 - accuracy: 0.9125 - val_loss: 1.6196 - val_accuracy: 0.5500\n",
      "Epoch 147/200\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2956 - accuracy: 0.9250 - val_loss: 1.6483 - val_accuracy: 0.5500\n",
      "Epoch 148/200\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2932 - accuracy: 0.9250 - val_loss: 1.6487 - val_accuracy: 0.5500\n",
      "Epoch 149/200\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2916 - accuracy: 0.9250 - val_loss: 1.6408 - val_accuracy: 0.5500\n",
      "Epoch 150/200\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2888 - accuracy: 0.9250 - val_loss: 1.6587 - val_accuracy: 0.5500\n",
      "Epoch 151/200\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.2867 - accuracy: 0.9250 - val_loss: 1.6648 - val_accuracy: 0.5500\n",
      "Epoch 152/200\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2843 - accuracy: 0.9250 - val_loss: 1.6639 - val_accuracy: 0.5500\n",
      "Epoch 153/200\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2816 - accuracy: 0.9250 - val_loss: 1.6804 - val_accuracy: 0.5500\n",
      "Epoch 154/200\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2801 - accuracy: 0.9250 - val_loss: 1.6740 - val_accuracy: 0.5500\n",
      "Epoch 155/200\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2782 - accuracy: 0.9250 - val_loss: 1.6923 - val_accuracy: 0.5500\n",
      "Epoch 156/200\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2769 - accuracy: 0.9250 - val_loss: 1.7137 - val_accuracy: 0.5500\n",
      "Epoch 157/200\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2739 - accuracy: 0.9250 - val_loss: 1.6972 - val_accuracy: 0.5500\n",
      "Epoch 158/200\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.2720 - accuracy: 0.9250 - val_loss: 1.7010 - val_accuracy: 0.5500\n",
      "Epoch 159/200\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2722 - accuracy: 0.9250 - val_loss: 1.7165 - val_accuracy: 0.5500\n",
      "Epoch 160/200\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2679 - accuracy: 0.9250 - val_loss: 1.7190 - val_accuracy: 0.5500\n",
      "Epoch 161/200\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2663 - accuracy: 0.9250 - val_loss: 1.7388 - val_accuracy: 0.5500\n",
      "Epoch 162/200\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2654 - accuracy: 0.9250 - val_loss: 1.7464 - val_accuracy: 0.5500\n",
      "Epoch 163/200\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2616 - accuracy: 0.9250 - val_loss: 1.7321 - val_accuracy: 0.5500\n",
      "Epoch 164/200\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2588 - accuracy: 0.9250 - val_loss: 1.7429 - val_accuracy: 0.5500\n",
      "Epoch 165/200\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2571 - accuracy: 0.9250 - val_loss: 1.7514 - val_accuracy: 0.5500\n",
      "Epoch 166/200\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2546 - accuracy: 0.9250 - val_loss: 1.7671 - val_accuracy: 0.5500\n",
      "Epoch 167/200\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2541 - accuracy: 0.9250 - val_loss: 1.7735 - val_accuracy: 0.5500\n",
      "Epoch 168/200\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2524 - accuracy: 0.9250 - val_loss: 1.8071 - val_accuracy: 0.5500\n",
      "Epoch 169/200\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2486 - accuracy: 0.9250 - val_loss: 1.7918 - val_accuracy: 0.5500\n",
      "Epoch 170/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.2475 - accuracy: 0.9250 - val_loss: 1.7806 - val_accuracy: 0.5500\n",
      "Epoch 171/200\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.2449 - accuracy: 0.9250 - val_loss: 1.7866 - val_accuracy: 0.5500\n",
      "Epoch 172/200\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2422 - accuracy: 0.9250 - val_loss: 1.8031 - val_accuracy: 0.5500\n",
      "Epoch 173/200\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2437 - accuracy: 0.9250 - val_loss: 1.8357 - val_accuracy: 0.5500\n",
      "Epoch 174/200\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2405 - accuracy: 0.9250 - val_loss: 1.8317 - val_accuracy: 0.5500\n",
      "Epoch 175/200\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2386 - accuracy: 0.9250 - val_loss: 1.8254 - val_accuracy: 0.5500\n",
      "Epoch 176/200\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2347 - accuracy: 0.9250 - val_loss: 1.8417 - val_accuracy: 0.5500\n",
      "Epoch 177/200\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2325 - accuracy: 0.9250 - val_loss: 1.8726 - val_accuracy: 0.5500\n",
      "Epoch 178/200\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2319 - accuracy: 0.9250 - val_loss: 1.8960 - val_accuracy: 0.5500\n",
      "Epoch 179/200\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2304 - accuracy: 0.9375 - val_loss: 1.8620 - val_accuracy: 0.5500\n",
      "Epoch 180/200\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2280 - accuracy: 0.9375 - val_loss: 1.8556 - val_accuracy: 0.5500\n",
      "Epoch 181/200\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2265 - accuracy: 0.9250 - val_loss: 1.8635 - val_accuracy: 0.5500\n",
      "Epoch 182/200\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2238 - accuracy: 0.9375 - val_loss: 1.9029 - val_accuracy: 0.5500\n",
      "Epoch 183/200\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.2228 - accuracy: 0.9375 - val_loss: 1.9191 - val_accuracy: 0.5500\n",
      "Epoch 184/200\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2192 - accuracy: 0.9375 - val_loss: 1.9206 - val_accuracy: 0.5500\n",
      "Epoch 185/200\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2172 - accuracy: 0.9375 - val_loss: 1.9248 - val_accuracy: 0.5000\n",
      "Epoch 186/200\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2154 - accuracy: 0.9375 - val_loss: 1.9289 - val_accuracy: 0.5000\n",
      "Epoch 187/200\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2135 - accuracy: 0.9375 - val_loss: 1.9394 - val_accuracy: 0.5000\n",
      "Epoch 188/200\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2115 - accuracy: 0.9375 - val_loss: 1.9377 - val_accuracy: 0.5000\n",
      "Epoch 189/200\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2121 - accuracy: 0.9375 - val_loss: 1.9733 - val_accuracy: 0.5000\n",
      "Epoch 190/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.2111 - accuracy: 0.9375 - val_loss: 1.9576 - val_accuracy: 0.5000\n",
      "Epoch 191/200\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2083 - accuracy: 0.9375 - val_loss: 1.9491 - val_accuracy: 0.5000\n",
      "Epoch 192/200\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2047 - accuracy: 0.9500 - val_loss: 1.9765 - val_accuracy: 0.5000\n",
      "Epoch 193/200\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2044 - accuracy: 0.9500 - val_loss: 2.0007 - val_accuracy: 0.5000\n",
      "Epoch 194/200\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2016 - accuracy: 0.9500 - val_loss: 1.9917 - val_accuracy: 0.5000\n",
      "Epoch 195/200\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2014 - accuracy: 0.9375 - val_loss: 1.9960 - val_accuracy: 0.5000\n",
      "Epoch 196/200\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1990 - accuracy: 0.9500 - val_loss: 2.0056 - val_accuracy: 0.5000\n",
      "Epoch 197/200\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1969 - accuracy: 0.9500 - val_loss: 1.9988 - val_accuracy: 0.5000\n",
      "Epoch 198/200\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1956 - accuracy: 0.9500 - val_loss: 2.0311 - val_accuracy: 0.5000\n",
      "Epoch 199/200\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1931 - accuracy: 0.9625 - val_loss: 2.0565 - val_accuracy: 0.5000\n",
      "Epoch 200/200\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1921 - accuracy: 0.9625 - val_loss: 2.0541 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x270bcdd9070>"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def preprocess_data(df, target_col=None):\n",
    "    df = df.drop(columns=['shop_id'])\n",
    "    if target_col is not None:\n",
    "        X = df.drop(columns=[target_col])\n",
    "        y = df[target_col]\n",
    "    else:\n",
    "        X = df\n",
    "        y = None\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "\n",
    "    if y is not None:\n",
    "        le = LabelEncoder()\n",
    "        y = le.fit_transform(y)\n",
    "    else:\n",
    "        le = None\n",
    "\n",
    "    return X, y, scaler, le\n",
    "\n",
    "def create_neural_network(input_dim, output_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_dim=input_dim, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(output_dim, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Preprocess the data and split it into training and validation sets\n",
    "store_profile_data = store_profile_data.dropna()\n",
    "X, y, _, le = preprocess_data(store_profile_data, target_col='shop_profile')\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and train the neural network\n",
    "input_dim = X_train.shape[1]\n",
    "output_dim = len(np.unique(y_train))\n",
    "model = create_neural_network(input_dim, output_dim)\n",
    "model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=200, batch_size=16)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "b94c3493",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "shop_id                   0\n",
       "shop_area_sq_ft           0\n",
       "shop_profile              0\n",
       "total_sales               0\n",
       "transaction_count         0\n",
       "unique_customers          0\n",
       "avg_transaction_value     0\n",
       "avg_sales_per_customer    0\n",
       "sales_per_sq_ft           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store_profile_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "15f6a61f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'store_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[230], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Prepare the test data\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m test_data \u001b[39m=\u001b[39m store_data[store_data[\u001b[39m'\u001b[39m\u001b[39mshop_profile\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39misnull()]\n\u001b[0;32m      3\u001b[0m X_test, _, _, _ \u001b[39m=\u001b[39m preprocess_data(test_data\u001b[39m.\u001b[39mdrop(columns\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mshop_profile\u001b[39m\u001b[39m'\u001b[39m), target_col\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n\u001b[0;32m      5\u001b[0m \u001b[39m# Make predictions on the test dataset\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'store_data' is not defined"
     ]
    }
   ],
   "source": [
    "# Prepare the test data\n",
    "test_data = store_data[store_data['shop_profile'].isnull()]\n",
    "X_test, _, _, _ = preprocess_data(test_data.drop(columns='shop_profile'), target_col=None)\n",
    "\n",
    "# Make predictions on the test dataset\n",
    "predicted_profiles = model.predict_classes(X_test)\n",
    "predicted_profiles = le.inverse_transform(predicted_profiles)\n",
    "\n",
    "# Combine the shop_id and the predicted shop profiles\n",
    "missing_shop_profiles = pd.DataFrame({'shop_id': test_data['shop_id'], 'shop_profile': predicted_profiles})\n",
    "\n",
    "# Save the missing shop profiles as a CSV file\n",
    "missing_shop_profiles.to_csv(\"predicted_missing_shop_profiles_nn.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "4b22c122",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Received incompatible tensor with shape (17, 32) when attempting to restore variable with shape (16, 32) and name dense_76/kernel:0.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[193], line 42\u001b[0m\n\u001b[0;32m     40\u001b[0m output_dim \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(np\u001b[39m.\u001b[39munique(y_train))\n\u001b[0;32m     41\u001b[0m model \u001b[39m=\u001b[39m create_neural_network(input_dim, output_dim)\n\u001b[1;32m---> 42\u001b[0m model\u001b[39m.\u001b[39;49mload_weights(\u001b[39m'\u001b[39;49m\u001b[39m./acc0.84/my_checkpoint\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     44\u001b[0m \u001b[39m# Prepare the test data\u001b[39;00m\n\u001b[0;32m     45\u001b[0m test_data \u001b[39m=\u001b[39m store_profile_data[store_profile_data[\u001b[39m'\u001b[39m\u001b[39mshop_profile\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39misnull()]\n",
      "File \u001b[1;32mc:\\Users\\naham\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\naham\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:720\u001b[0m, in \u001b[0;36mBaseResourceVariable._restore_from_tensors\u001b[1;34m(self, restored_tensors)\u001b[0m\n\u001b[0;32m    717\u001b[0m   assigned_variable \u001b[39m=\u001b[39m shape_safe_assign_variable_handle(\n\u001b[0;32m    718\u001b[0m       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshape, restored_tensor)\n\u001b[0;32m    719\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m--> 720\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    721\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mReceived incompatible tensor with shape \u001b[39m\u001b[39m{\u001b[39;00mrestored_tensor\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    722\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwhen attempting to restore variable with shape \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    723\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mand name \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[0;32m    724\u001b[0m \u001b[39mreturn\u001b[39;00m assigned_variable\n",
      "\u001b[1;31mValueError\u001b[0m: Received incompatible tensor with shape (17, 32) when attempting to restore variable with shape (16, 32) and name dense_76/kernel:0."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "def preprocess_data(df, target_col=None):\n",
    "    df = df.drop(columns=['shop_id'])\n",
    "    if target_col is not None:\n",
    "        X = df.drop(columns=[target_col])\n",
    "        y = df[target_col]\n",
    "    else:\n",
    "        X = df\n",
    "        y = None\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "\n",
    "    if y is not None:\n",
    "        le = LabelEncoder()\n",
    "        y = le.fit_transform(y)\n",
    "    else:\n",
    "        le = None\n",
    "\n",
    "    return X, y, scaler, le\n",
    "\n",
    "def create_neural_network(input_dim, output_dim):\n",
    "   model = Sequential()\n",
    "   model.add(Dense(32, activation='relu', input_dim=X_train_scaled.shape[1]))\n",
    "   model.add(Dropout(0.2))\n",
    "   model.add(Dense(16, activation='relu'))\n",
    "   model.add(Dropout(0.2))\n",
    "   model.add(Dense(8, activation='relu'))\n",
    "   model.add(Dense(len(encoder.classes_), activation='softmax'))\n",
    "   model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "   return model\n",
    "\n",
    "# Load the saved model\n",
    "input_dim = X_train.shape[1]\n",
    "output_dim = len(np.unique(y_train))\n",
    "model = create_neural_network(input_dim, output_dim)\n",
    "model.load_weights('./acc0.84/my_checkpoint')\n",
    "\n",
    "# Prepare the test data\n",
    "test_data = store_profile_data[store_profile_data['shop_profile'].isnull()]\n",
    "X_test, _, _, _ = preprocess_data(test_data.drop(columns='shop_profile'), target_col=None)\n",
    "\n",
    "# Make predictions on the test dataset\n",
    "predicted_profiles = model.predict_classes(X_test)\n",
    "predicted_profiles = le.inverse_transform(predicted_profiles)\n",
    "\n",
    "# Combine the shop_id and the predicted shop profiles\n",
    "missing_shop_profiles = pd.DataFrame({'shop_id': test_data['shop_id'], 'shop_profile': predicted_profiles})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "1da1a145",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "def create_neural_network(input_dim, output_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(32, activation='relu', input_dim=input_dim))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(output_dim, activation='softmax'))\n",
    "    \n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "66046cef",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Received incompatible tensor with shape (17, 32) when attempting to restore variable with shape (16, 32) and name dense_80/kernel:0.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[195], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m output_dim \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(np\u001b[39m.\u001b[39munique(y_train))\n\u001b[0;32m      3\u001b[0m model \u001b[39m=\u001b[39m create_neural_network(input_dim, output_dim)\n\u001b[1;32m----> 4\u001b[0m model\u001b[39m.\u001b[39;49mload_weights(\u001b[39m'\u001b[39;49m\u001b[39m./acc0.84/my_checkpoint\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      6\u001b[0m \u001b[39m# Prepare the test data\u001b[39;00m\n\u001b[0;32m      7\u001b[0m test_data \u001b[39m=\u001b[39m store_profile_data[store_profile_data[\u001b[39m'\u001b[39m\u001b[39mshop_profile\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39misnull()]\n",
      "File \u001b[1;32mc:\\Users\\naham\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\naham\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:720\u001b[0m, in \u001b[0;36mBaseResourceVariable._restore_from_tensors\u001b[1;34m(self, restored_tensors)\u001b[0m\n\u001b[0;32m    717\u001b[0m   assigned_variable \u001b[39m=\u001b[39m shape_safe_assign_variable_handle(\n\u001b[0;32m    718\u001b[0m       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshape, restored_tensor)\n\u001b[0;32m    719\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m--> 720\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    721\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mReceived incompatible tensor with shape \u001b[39m\u001b[39m{\u001b[39;00mrestored_tensor\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    722\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwhen attempting to restore variable with shape \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    723\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mand name \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[0;32m    724\u001b[0m \u001b[39mreturn\u001b[39;00m assigned_variable\n",
      "\u001b[1;31mValueError\u001b[0m: Received incompatible tensor with shape (17, 32) when attempting to restore variable with shape (16, 32) and name dense_80/kernel:0."
     ]
    }
   ],
   "source": [
    "input_dim = X_train.shape[1]\n",
    "output_dim = len(np.unique(y_train))\n",
    "model = create_neural_network(input_dim, output_dim)\n",
    "model.load_weights('./acc0.84/my_checkpoint')\n",
    "\n",
    "# Prepare the test data\n",
    "test_data = store_profile_data[store_profile_data['shop_profile'].isnull()]\n",
    "X_test = test_data.drop(columns=['shop_id', 'shop_profile'])\n",
    "\n",
    "# Preprocess the test data\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Make predictions on the test dataset\n",
    "predicted_profiles = model.predict(X_test_scaled)\n",
    "predicted_profiles = np.argmax(predicted_profiles, axis=1)\n",
    "predicted_labels = encoder.inverse_transform(predicted_profiles)\n",
    "\n",
    "# Create a DataFrame with the shop_id and predicted shop_profile\n",
    "missing_shop_profiles = pd.DataFrame({'shop_id': test_data['shop_id'], 'shop_profile': predicted_labels})\n",
    "\n",
    "# Save the missing_shop_profiles DataFrame to a CSV file\n",
    "missing_shop_profiles.to_csv('missing_shop_profiles.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11da2217",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
